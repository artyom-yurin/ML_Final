{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Final_project.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "alcR_GzulqsI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.autograd import Function\n",
        "\n",
        "\n",
        "class ReverseLayerF(Function):\n",
        "\n",
        "    @staticmethod\n",
        "    def forward(ctx, x, alpha):\n",
        "        ctx.alpha = alpha\n",
        "\n",
        "        return x.view_as(x)\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        output = grad_output.neg() * ctx.alpha\n",
        "        return output, None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JFr4F7BIXEcw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def save_model(net, model_root, filename):\n",
        "    \"\"\"Save trained model.\"\"\"\n",
        "    if not os.path.exists(model_root):\n",
        "        os.makedirs(model_root)\n",
        "    torch.save(net.state_dict(), os.path.join(model_root, filename))\n",
        "    print(\"save pretrained model to: {}\".format(os.path.join(model_root, filename)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S0zM7N-lls92",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "from torchvision import models\n",
        "\n",
        "class SVHNmodel(nn.Module):\n",
        "    \"\"\" SVHN architecture\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        super(SVHNmodel, self).__init__()\n",
        "        self.restored = False\n",
        "\n",
        "        self.feature = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=3, out_channels=64, kernel_size=(5, 5)),  # 28\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=(3, 3), stride=(2, 2)),  # 13\n",
        "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=(5, 5)),  # 9\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.Dropout2d(),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=(3, 3), stride=(2, 2)),  # 4\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=(4, 4)),  # 1\n",
        "        )\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(128 * 1 * 1, 1024),\n",
        "            nn.BatchNorm1d(1024),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(1024, 256),\n",
        "            nn.BatchNorm1d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(256, 10),\n",
        "        )\n",
        "\n",
        "        self.discriminator = nn.Sequential(\n",
        "            nn.Linear(128 * 1 * 1, 1024),\n",
        "            nn.BatchNorm1d(1024),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(1024, 256),\n",
        "            nn.BatchNorm1d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(256, 2),\n",
        "        )\n",
        "\n",
        "    def forward(self, input_data, alpha = 1.0):\n",
        "        input_data = input_data.expand(input_data.data.shape[0], 3, 32, 32)\n",
        "        feature = self.feature(input_data)\n",
        "        feature = feature.view(-1, 128 * 1 * 1)\n",
        "        reverse_feature = ReverseLayerF.apply(feature, alpha)\n",
        "        class_output = self.classifier(feature)\n",
        "        domain_output = self.discriminator(reverse_feature)\n",
        "\n",
        "        return class_output, domain_output\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2gUxpcYyluMN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "import torch.utils.data\n",
        "import torch.nn as nn\n",
        "\n",
        "def test(model, data_loader, device, flag):\n",
        "    \"\"\"Evaluate model for dataset.\"\"\"\n",
        "    # set eval state for Dropout and BN layers\n",
        "    model.eval()\n",
        "\n",
        "    # init loss and accuracy\n",
        "    loss_ = 0.0\n",
        "    acc_ = 0.0\n",
        "    acc_domain_ = 0.0\n",
        "    n_total = 0\n",
        "\n",
        "    # set loss function\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    # evaluate network\n",
        "    for (images, labels) in data_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device) \n",
        "        size = len(labels)\n",
        "        if flag == 'target':\n",
        "            labels_domain = torch.ones(size).long().to(device)\n",
        "        else:\n",
        "            labels_domain = torch.zeros(size).long().to(device)\n",
        "\n",
        "        preds, domain = model(images, alpha=0)\n",
        "        loss_ += criterion(preds, labels).item()\n",
        "\n",
        "        pred_cls = preds.data.max(1)[1]\n",
        "        pred_domain = domain.data.max(1)[1]\n",
        "        acc_ += pred_cls.eq(labels.data).sum().item()\n",
        "        acc_domain_ += pred_domain.eq(labels_domain.data).sum().item()\n",
        "        n_total += size\n",
        "\n",
        "    loss = loss_ / n_total\n",
        "    acc = acc_ / n_total\n",
        "    acc_domain = acc_domain_ / n_total\n",
        "\n",
        "    print(\"Avg Loss = {:.6f}, Avg Accuracy = {:.2%}, {}/{}, Avg Domain Accuracy = {:2%}\".format(loss, acc, acc_, n_total, acc_domain))\n",
        "\n",
        "    return loss, acc, acc_domain"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pbo---Zdrbir",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def adjust_learning_rate(optimizer, p):\n",
        "    lr_0 = 0.01\n",
        "    alpha = 10\n",
        "    beta = 0.75\n",
        "    lr = lr_0 / (1 + alpha * p)**beta\n",
        "    for param_group in optimizer.param_groups:\n",
        "        param_group['lr'] = lr\n",
        "    return lr\n",
        "\n",
        "def adjust_learning_rate_office(optimizer, p):\n",
        "    lr_0 = 0.001\n",
        "    alpha = 10\n",
        "    beta = 0.75\n",
        "    lr = lr_0 / (1 + alpha * p)**beta\n",
        "    for param_group in optimizer.param_groups[:2]:\n",
        "        param_group['lr'] = lr\n",
        "    for param_group in optimizer.param_groups[2:]:\n",
        "        param_group['lr'] = 10 * lr\n",
        "    return lr"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9zIb86Kolvns",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"Train dann.\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.backends.cudnn as cudnn\n",
        "cudnn.benchmark = True\n",
        "\n",
        "def train_dann(model, params, src_data_loader, tgt_data_loader, tgt_data_loader_eval, device, logger):\n",
        "    \"\"\"Train dann.\"\"\"\n",
        "    ####################\n",
        "    # 1. setup network #\n",
        "    ####################\n",
        "\n",
        "    # setup criterion and optimizer\n",
        "    optimizer = optim.Adam(model.parameters(), lr=params.lr, betas=(params.beta1, 0.999))\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    ####################\n",
        "    # 2. train network #\n",
        "    ####################\n",
        "    global_step = 0\n",
        "    for epoch in range(params.num_epochs):\n",
        "        # set train state for Dropout and BN layers\n",
        "        model.train()\n",
        "        # zip source and target data pair\n",
        "        len_dataloader = min(len(src_data_loader), len(tgt_data_loader))\n",
        "        data_zip = enumerate(zip(src_data_loader, tgt_data_loader))\n",
        "        for step, ((images_src, class_src), (images_tgt, _)) in data_zip:\n",
        "\n",
        "            p = float(step + epoch * len_dataloader) / \\\n",
        "                params.num_epochs / len_dataloader\n",
        "            alpha = 2. / (1. + np.exp(-10 * p)) - 1\n",
        "\n",
        "            lr = adjust_learning_rate(optimizer, p)\n",
        "            logger.add_scalar('lr', lr, global_step)\n",
        "\n",
        "            # prepare domain label\n",
        "            size_src = len(images_src)\n",
        "            size_tgt = len(images_tgt)\n",
        "            label_src = torch.zeros(size_src).long().to(device)  # source 0\n",
        "            label_tgt = torch.ones(size_tgt).long().to(device)  # target 1\n",
        "\n",
        "            # make images variable\n",
        "            class_src = class_src.to(device)\n",
        "            images_src = images_src.to(device)\n",
        "            images_tgt = images_tgt.to(device)\n",
        "\n",
        "            # zero gradients for optimizer\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # train on source domain\n",
        "            src_class_output, src_domain_output = model(input_data=images_src, alpha=alpha)\n",
        "            src_loss_class = criterion(src_class_output, class_src)\n",
        "            src_loss_domain = criterion(src_domain_output, label_src)\n",
        "\n",
        "            # train on target domain\n",
        "            _, tgt_domain_output = model(input_data=images_tgt, alpha=alpha)\n",
        "            tgt_loss_domain = criterion(tgt_domain_output, label_tgt)\n",
        "\n",
        "\n",
        "            loss = src_loss_class + src_loss_domain + tgt_loss_domain\n",
        "            if params.src_only_flag:\n",
        "                loss = src_loss_class\n",
        "\n",
        "            # optimize dann\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            global_step += 1\n",
        "\n",
        "            # print step info\n",
        "            logger.add_scalar('src_loss_class', src_loss_class.item(), global_step)\n",
        "            logger.add_scalar('src_loss_domain', src_loss_domain.item(), global_step)\n",
        "            logger.add_scalar('tgt_loss_domain', tgt_loss_domain.item(), global_step)\n",
        "            logger.add_scalar('loss', loss.item(), global_step)\n",
        "\n",
        "            if ((step + 1) % params.log_step == 0):\n",
        "                print(\n",
        "                    \"Epoch [{:4d}/{}] Step [{:2d}/{}]: src_loss_class={:.6f}, src_loss_domain={:.6f}, tgt_loss_domain={:.6f}, loss={:.6f}\"\n",
        "                    .format(epoch + 1, params.num_epochs, step + 1, len_dataloader, src_loss_class.data.item(),\n",
        "                            src_loss_domain.data.item(), tgt_loss_domain.data.item(), loss.data.item()))\n",
        "\n",
        "        # eval model\n",
        "        if ((epoch + 1) % params.eval_step == 0):\n",
        "            print(\"Train SVHN score\")\n",
        "            src_train_loss, src_tr_acc, src_tr_acc_domain = test(model, src_data_loader, device, flag='source')\n",
        "            print(\"Test SVHN score\")\n",
        "            src_test_loss, src_acc, src_acc_domain = test(model, src_data_loader_eval, device, flag='source')\n",
        "            print(\"Test MNIST score\")\n",
        "            tgt_test_loss, tgt_acc, tgt_acc_domain = test(model, tgt_data_loader_eval, device, flag='target')\n",
        "            logger.add_scalar('src_test_loss', src_test_loss, global_step)\n",
        "            logger.add_scalar('src_acc', src_acc, global_step)\n",
        "            logger.add_scalar('src_acc_domain', src_acc_domain, global_step)\n",
        "            logger.add_scalar('tgt_test_loss', tgt_test_loss, global_step)\n",
        "            logger.add_scalar('tgt_acc', tgt_acc, global_step)\n",
        "            logger.add_scalar('tgt_acc_domain', tgt_acc_domain, global_step)\n",
        "\n",
        "\n",
        "        # save model parameters\n",
        "        if ((epoch + 1) % params.save_step == 0):\n",
        "            save_model(model, params.model_root, params.src_dataset + '-' + params.tgt_dataset + \"-dann-{}.pt\".format(epoch + 1))\n",
        "\n",
        "    #save final model\n",
        "    save_model(model, params.model_root, params.src_dataset + '-' + params.tgt_dataset + \"-dann-final.pt\")\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OGx8s1crlxDV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import torch.backends.cudnn as cudnn\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "def init_weights(m):\n",
        "    if type(m) == nn.Conv2d:\n",
        "        nn.init.xavier_normal_(m.weight)\n",
        "    if type(m) == nn.Linear:\n",
        "        nn.init.xavier_normal_(m.weight)\n",
        "\n",
        "def init_model(net, restore):\n",
        "    \"\"\"Init models with cuda and weights.\"\"\"\n",
        "    # init weights of model\n",
        "    net.apply(init_weights)\n",
        "\n",
        "    # check if cuda is available\n",
        "    if torch.cuda.is_available():\n",
        "        cudnn.benchmark = True\n",
        "        net.cuda()\n",
        "\n",
        "    return net\n",
        "\n",
        "def init_random_seed(manual_seed):\n",
        "    \"\"\"Init random seed.\"\"\"\n",
        "    seed = None\n",
        "    if manual_seed is None:\n",
        "        seed = random.randint(1, 10000)\n",
        "    else:\n",
        "        seed = manual_seed\n",
        "    print(\"use random seed: {}\".format(seed))\n",
        "    random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "        \n",
        "def get_data_loader(name, dataset_root, batch_size, train=True):\n",
        "    \"\"\"Get data loader by name.\"\"\"\n",
        "    if name == \"mnist\":\n",
        "        return get_mnist(dataset_root, batch_size, train)\n",
        "    elif name == \"svhn\":\n",
        "        return get_svhn(dataset_root, batch_size, train)\n",
        "    \n",
        "def get_svhn(dataset_root, batch_size, train):\n",
        "    \"\"\"Get SVHN datasets loader.\"\"\"\n",
        "    # image pre-processing\n",
        "    pre_process = transforms.Compose([transforms.Resize(32),\n",
        "                                      transforms.ToTensor(),\n",
        "                                      transforms.Normalize(\n",
        "                                          mean=(0.5, 0.5, 0.5),\n",
        "                                          std=(0.5, 0.5, 0.5)\n",
        "                                      )])\n",
        "\n",
        "    # datasets and data loader\n",
        "    if train:\n",
        "        svhn_dataset = datasets.SVHN(root=os.path.join(dataset_root),\n",
        "                                   split='train',\n",
        "                                   download=True,  \n",
        "                                   transform=pre_process)\n",
        "    else:\n",
        "        svhn_dataset = datasets.SVHN(root=os.path.join(dataset_root),\n",
        "                                   split='test',\n",
        "                                   download=True,\n",
        "                                   transform=pre_process)\n",
        "\n",
        "    svhn_data_loader = torch.utils.data.DataLoader(\n",
        "        dataset=svhn_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True,\n",
        "        drop_last=True)\n",
        "\n",
        "    return svhn_data_loader\n",
        "\n",
        "def get_mnist(dataset_root, batch_size, train):\n",
        "    \"\"\"Get MNIST datasets loader.\"\"\"\n",
        "    # image pre-processing\n",
        "    pre_process = transforms.Compose([transforms.Resize(32), # different img size settings for mnist(28) and svhn(32).\n",
        "                                      transforms.Grayscale(num_output_channels=3),\n",
        "                                      transforms.ToTensor(),\n",
        "                                      transforms.Normalize(\n",
        "                                          mean=(0.5, 0.5, 0.5),\n",
        "                                          std=(0.5, 0.5, 0.5)\n",
        "                                      )])\n",
        "\n",
        "    # datasets and data loader\n",
        "    mnist_dataset = datasets.MNIST(root=os.path.join(dataset_root),\n",
        "                                   train=train,\n",
        "                                   download=True,\n",
        "                                   transform=pre_process)\n",
        "\n",
        "\n",
        "    mnist_data_loader = torch.utils.data.DataLoader(\n",
        "        dataset=mnist_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True,\n",
        "        drop_last=True,\n",
        "        num_workers=8)\n",
        "\n",
        "    return mnist_data_loader"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "56lRClp7lzcQ",
        "colab_type": "code",
        "outputId": "23f6101d-f839-46af-fe7b-846e4c3df449",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import os\n",
        "import sys\n",
        "import datetime\n",
        "import multiprocessing\n",
        "from torch.utils import tensorboard\n",
        "import torch\n",
        "\n",
        "\n",
        "class Config(object):\n",
        "    # params for path\n",
        "    model_name = \"svhn-mnist\"\n",
        "    model_base = '../data'\n",
        "    model_root = os.path.expanduser(os.path.join('~', 'Models', 'pytorch-DANN', model_name))\n",
        "    note = 'paper-structure'\n",
        "    model_root = os.path.join(model_base, model_name, note + '_' + datetime.datetime.now().strftime('%m%d_%H%M%S'))\n",
        "    os.makedirs(model_root)\n",
        "    config = os.path.join(model_root, 'config.txt')\n",
        "    finetune_flag = False\n",
        "    lr_adjust_flag = 'simple'\n",
        "    src_only_flag = False\n",
        "\n",
        "    # params for datasets and data loader\n",
        "    batch_size = 128\n",
        "\n",
        "    # params for source dataset\n",
        "    src_dataset = \"svhn\"\n",
        "    src_image_root = os.path.join('../data', 'svhn')\n",
        "    src_model_trained = True\n",
        "    src_classifier_restore = os.path.join(model_root, src_dataset + '-source-classifier-final.pt')\n",
        "\n",
        "    # params for target dataset\n",
        "    tgt_dataset = \"mnist\"\n",
        "    tgt_image_root = os.path.join('../data', 'mnist')\n",
        "    tgt_model_trained = True\n",
        "    dann_restore = os.path.join(model_root, src_dataset + '-' + tgt_dataset + '-dann-final.pt')\n",
        "\n",
        "    # params for training dann\n",
        "    gpu_id = '0'\n",
        "\n",
        "    ## for digit\n",
        "    num_epochs = 50\n",
        "    log_step = 50\n",
        "    save_step = 100\n",
        "    eval_step = 1\n",
        "\n",
        "    manual_seed = None\n",
        "    alpha = 0\n",
        "\n",
        "    # params for optimizing models\n",
        "    lr = 0.01\n",
        "    beta1 = 0.5\n",
        "\n",
        "    def __init__(self):\n",
        "        public_props = (name for name in dir(self) if not name.startswith('_'))\n",
        "        with open(self.config, 'w') as f:\n",
        "            for name in public_props:\n",
        "                f.write(name + ': ' + str(getattr(self, name)) + '\\n')\n",
        "\n",
        "params = Config()\n",
        "logger = tensorboard.SummaryWriter(params.model_root)\n",
        "device = torch.device(\"cuda:\" + params.gpu_id if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# init random seed\n",
        "init_random_seed(params.manual_seed)\n",
        "\n",
        "# load dataset\n",
        "src_data_loader = get_data_loader(params.src_dataset, params.src_image_root, params.batch_size, train=True)\n",
        "src_data_loader_eval = get_data_loader(params.src_dataset, params.src_image_root, params.batch_size, train=False)\n",
        "tgt_data_loader = get_data_loader(params.tgt_dataset, params.tgt_image_root, params.batch_size, train=True)\n",
        "tgt_data_loader_eval = get_data_loader(params.tgt_dataset, params.tgt_image_root, params.batch_size, train=False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "use random seed: 5222\n",
            "Downloading http://ufldl.stanford.edu/housenumbers/train_32x32.mat to ../data/svhn/train_32x32.mat\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|█████████▉| 181174272/182040794 [00:15<00:00, 17099985.85it/s]\n",
            "0it [00:00, ?it/s]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://ufldl.stanford.edu/housenumbers/test_32x32.mat to ../data/svhn/test_32x32.mat\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/64275384 [00:00<?, ?it/s]\u001b[A\n",
            "  0%|          | 16384/64275384 [00:00<11:02, 96966.77it/s]\u001b[A\n",
            "  0%|          | 32768/64275384 [00:00<11:02, 96912.53it/s]\u001b[A\n",
            "  0%|          | 57344/64275384 [00:00<09:56, 107643.37it/s]\u001b[A\n",
            "  0%|          | 90112/64275384 [00:01<08:37, 124110.95it/s]\u001b[A\n",
            "  0%|          | 139264/64275384 [00:01<07:08, 149837.71it/s]\u001b[A\n",
            "  0%|          | 188416/64275384 [00:01<06:05, 175298.34it/s]\u001b[A\n",
            "  0%|          | 245760/64275384 [00:01<05:12, 204935.67it/s]\u001b[A\n",
            "  0%|          | 311296/64275384 [00:01<04:28, 238623.73it/s]\u001b[A\n",
            "  1%|          | 376832/64275384 [00:01<03:56, 269656.17it/s]\u001b[A\n",
            "  1%|          | 458752/64275384 [00:02<03:25, 311010.69it/s]\u001b[A\n",
            "  1%|          | 557056/64275384 [00:02<02:56, 361339.04it/s]\u001b[A\n",
            "  1%|          | 655360/64275384 [00:02<02:36, 407534.97it/s]\u001b[A\n",
            "  1%|          | 786432/64275384 [00:02<02:13, 475011.77it/s]\u001b[A\n",
            "  1%|▏         | 933888/64275384 [00:02<01:55, 549938.10it/s]\u001b[A\n",
            "  2%|▏         | 1122304/64275384 [00:02<01:37, 648208.17it/s]\u001b[A\n",
            "  2%|▏         | 1359872/64275384 [00:03<01:21, 772952.84it/s]\u001b[A\n",
            "  3%|▎         | 1630208/64275384 [00:03<01:08, 914019.58it/s]\u001b[A\n",
            "  3%|▎         | 1966080/64275384 [00:03<00:57, 1090974.81it/s]\u001b[A\n",
            "  4%|▎         | 2334720/64275384 [00:03<00:48, 1283055.93it/s]\u001b[A\n",
            "  4%|▍         | 2785280/64275384 [00:03<00:40, 1519157.26it/s]\u001b[A\n",
            "  5%|▌         | 3317760/64275384 [00:03<00:33, 1797641.07it/s]\u001b[A\n",
            "  6%|▌         | 3915776/64275384 [00:04<00:28, 2107970.22it/s]\u001b[A\n",
            "  7%|▋         | 4571136/64275384 [00:04<00:24, 2441783.37it/s]\u001b[A\n",
            "  8%|▊         | 5316608/64275384 [00:04<00:20, 2818371.30it/s]\u001b[A\n",
            " 10%|▉         | 6193152/64275384 [00:04<00:17, 3264866.81it/s]\u001b[A\n",
            " 11%|█▏        | 7249920/64275384 [00:04<00:14, 3810589.50it/s]\u001b[A\n",
            " 13%|█▎        | 8544256/64275384 [00:04<00:12, 4485766.67it/s]\u001b[A\n",
            " 16%|█▌        | 10158080/64275384 [00:05<00:10, 5332514.78it/s]\u001b[A\n",
            " 19%|█▊        | 12034048/64275384 [00:05<00:08, 6315984.84it/s]\u001b[A\n",
            " 22%|██▏       | 14262272/64275384 [00:05<00:06, 7483298.26it/s]\u001b[A\n",
            " 26%|██▌       | 16818176/64275384 [00:05<00:05, 8817308.90it/s]\u001b[A\n",
            " 31%|███       | 19636224/64275384 [00:05<00:04, 10265842.27it/s]\u001b[A\n",
            " 35%|███▌      | 22528000/64275384 [00:05<00:03, 11660144.42it/s]\u001b[A\n",
            " 40%|███▉      | 25550848/64275384 [00:06<00:02, 13015701.38it/s]\u001b[A\n",
            " 45%|████▍     | 28696576/64275384 [00:06<00:02, 14143738.58it/s]\u001b[A\n",
            " 50%|████▉     | 31825920/64275384 [00:06<00:02, 15398545.36it/s]\u001b[A\n",
            " 54%|█████▍    | 34963456/64275384 [00:06<00:01, 16219894.60it/s]\u001b[A\n",
            " 59%|█████▉    | 38100992/64275384 [00:06<00:01, 16855761.04it/s]\u001b[A\n",
            " 64%|██████▍   | 41009152/64275384 [00:06<00:01, 16149576.68it/s]\u001b[A\n",
            " 68%|██████▊   | 43941888/64275384 [00:07<00:01, 16418406.14it/s]\u001b[A\n",
            " 73%|███████▎  | 46850048/64275384 [00:07<00:01, 16548046.70it/s]\u001b[A\n",
            " 78%|███████▊  | 49897472/64275384 [00:07<00:00, 16875522.04it/s]\u001b[A\n",
            " 82%|████████▏ | 52756480/64275384 [00:07<00:00, 16746010.35it/s]\u001b[A\n",
            " 87%|████████▋ | 55885824/64275384 [00:07<00:00, 17235903.91it/s]\u001b[A\n",
            " 92%|█████████▏| 58949632/64275384 [00:08<00:00, 17250704.26it/s]\u001b[A\n",
            " 97%|█████████▋| 62078976/64275384 [00:08<00:00, 17563763.94it/s]\u001b[A\n",
            "\n",
            "0it [00:00, ?it/s]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ../data/mnist/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "  0%|          | 0/9912422 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "  0%|          | 16384/9912422 [00:00<02:28, 66455.73it/s]\u001b[A\u001b[A\n",
            "\n",
            "  0%|          | 40960/9912422 [00:01<02:10, 75899.63it/s]\u001b[A\u001b[A\n",
            "\n",
            "  1%|          | 98304/9912422 [00:01<01:41, 96479.41it/s]\u001b[A\u001b[A\n",
            "\n",
            "  2%|▏         | 212992/9912422 [00:01<01:15, 127846.27it/s]\u001b[A\u001b[A\n",
            "\n",
            "  4%|▍         | 425984/9912422 [00:01<00:54, 173096.65it/s]\u001b[A\u001b[A\n",
            "\n",
            "  6%|▌         | 614400/9912422 [00:02<00:40, 228040.03it/s]\u001b[A\u001b[A\n",
            "\n",
            " 10%|█         | 1024000/9912422 [00:02<00:28, 309909.95it/s]\u001b[A\u001b[A\n",
            "\n",
            " 19%|█▉        | 1884160/9912422 [00:02<00:18, 428479.06it/s]\u001b[A\u001b[A\n",
            "\n",
            " 35%|███▍      | 3457024/9912422 [00:02<00:10, 597227.88it/s]\u001b[A\u001b[A\n",
            "\n",
            " 63%|██████▎   | 6234112/9912422 [00:02<00:04, 836645.80it/s]\u001b[A\u001b[A\n",
            "\n",
            " 95%|█████████▍| 9379840/9912422 [00:03<00:00, 1166683.46it/s]\u001b[A\u001b[A\n",
            "\n",
            "9920512it [00:03, 3198329.01it/s]                             \u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ../data/mnist/MNIST/raw/train-images-idx3-ubyte.gz to ../data/mnist/MNIST/raw\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r182042624it [00:30, 17099985.85it/s]                               \n",
            "\n",
            "0it [00:00, ?it/s]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ../data/mnist/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "  0%|          | 0/28881 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            " 57%|█████▋    | 16384/28881 [00:00<00:00, 73404.13it/s]\u001b[A\u001b[A\n",
            "\n",
            "32768it [00:00, 48822.95it/s]                           \u001b[A\u001b[A\n",
            "\n",
            "0it [00:00, ?it/s]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ../data/mnist/MNIST/raw/train-labels-idx1-ubyte.gz to ../data/mnist/MNIST/raw\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ../data/mnist/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "  0%|          | 0/1648877 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "  1%|          | 16384/1648877 [00:00<00:24, 65620.11it/s]\u001b[A\u001b[A\n",
            "\n",
            "  2%|▏         | 40960/1648877 [00:00<00:21, 74938.88it/s]\u001b[A\u001b[A\n",
            "\n",
            "  6%|▌         | 98304/1648877 [00:01<00:16, 95246.52it/s]\u001b[A\u001b[A\n",
            "\n",
            " 13%|█▎        | 212992/1648877 [00:01<00:11, 126215.19it/s]\u001b[A\u001b[A\n",
            "\n",
            " 26%|██▌       | 425984/1648877 [00:01<00:07, 170883.02it/s]\u001b[A\u001b[A\n",
            "\n",
            " 38%|███▊      | 622592/1648877 [00:01<00:04, 225837.81it/s]\u001b[A\u001b[A\n",
            "\n",
            " 62%|██████▏   | 1024000/1648877 [00:02<00:02, 306478.54it/s]\u001b[A\u001b[A\n",
            "\n",
            "1654784it [00:02, 816172.58it/s]                             \u001b[A\u001b[A\n",
            "\n",
            "0it [00:00, ?it/s]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ../data/mnist/MNIST/raw/t10k-images-idx3-ubyte.gz to ../data/mnist/MNIST/raw\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ../data/mnist/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "  0%|          | 0/4542 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "8192it [00:00, 18705.81it/s]            \u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ../data/mnist/MNIST/raw/t10k-labels-idx1-ubyte.gz to ../data/mnist/MNIST/raw\n",
            "Processing...\n",
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2E8HyvJ5i21J",
        "colab_type": "code",
        "outputId": "eda968d0-96a2-41b7-8f68-ef6817c7a46c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# load dann model\n",
        "dann = init_model(net=SVHNmodel(), restore=None)\n",
        "\n",
        "# train dann model\n",
        "print(\"Training dann model\")\n",
        "dann = train_dann(dann, params, src_data_loader, tgt_data_loader, tgt_data_loader_eval, device, logger)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "64282624it [00:22, 17563763.94it/s]                              \u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training dann model\n",
            "Epoch [   1/50] Step [50/468]: src_loss_class=1.794217, src_loss_domain=0.505048, tgt_loss_domain=0.509467, loss=2.808732\n",
            "Epoch [   1/50] Step [100/468]: src_loss_class=1.230935, src_loss_domain=0.280223, tgt_loss_domain=0.190053, loss=1.701211\n",
            "Epoch [   1/50] Step [150/468]: src_loss_class=0.943820, src_loss_domain=0.066955, tgt_loss_domain=0.262523, loss=1.273298\n",
            "Epoch [   1/50] Step [200/468]: src_loss_class=0.866094, src_loss_domain=0.060876, tgt_loss_domain=0.130522, loss=1.057492\n",
            "Epoch [   1/50] Step [250/468]: src_loss_class=0.723378, src_loss_domain=0.671953, tgt_loss_domain=0.039317, loss=1.434648\n",
            "Epoch [   1/50] Step [300/468]: src_loss_class=0.628017, src_loss_domain=0.167799, tgt_loss_domain=0.225468, loss=1.021284\n",
            "Epoch [   1/50] Step [350/468]: src_loss_class=0.847219, src_loss_domain=0.113404, tgt_loss_domain=0.182628, loss=1.143251\n",
            "Epoch [   1/50] Step [400/468]: src_loss_class=0.731506, src_loss_domain=0.514285, tgt_loss_domain=0.614318, loss=1.860110\n",
            "Epoch [   1/50] Step [450/468]: src_loss_class=0.594821, src_loss_domain=0.711021, tgt_loss_domain=0.364373, loss=1.670215\n",
            "Train SVHN score\n",
            "Avg Loss = 0.007366, Avg Accuracy = 68.65%, 50261.0/73216, Avg Domain Accuracy = 77.084244%\n",
            "Test SVHN score\n",
            "Avg Loss = 0.007270, Avg Accuracy = 68.80%, 17877.0/25984, Avg Domain Accuracy = 75.227063%\n",
            "Test MNIST score\n",
            "Avg Loss = 0.011429, Avg Accuracy = 56.90%, 5681.0/9984, Avg Domain Accuracy = 44.100561%\n",
            "Epoch [   2/50] Step [50/468]: src_loss_class=0.813017, src_loss_domain=0.705167, tgt_loss_domain=0.323825, loss=1.842010\n",
            "Epoch [   2/50] Step [100/468]: src_loss_class=0.650093, src_loss_domain=0.535342, tgt_loss_domain=0.673447, loss=1.858882\n",
            "Epoch [   2/50] Step [150/468]: src_loss_class=0.691161, src_loss_domain=0.617050, tgt_loss_domain=0.408032, loss=1.716243\n",
            "Epoch [   2/50] Step [200/468]: src_loss_class=0.803701, src_loss_domain=0.385350, tgt_loss_domain=1.090691, loss=2.279742\n",
            "Epoch [   2/50] Step [250/468]: src_loss_class=0.587964, src_loss_domain=0.582735, tgt_loss_domain=0.726158, loss=1.896857\n",
            "Epoch [   2/50] Step [300/468]: src_loss_class=0.742178, src_loss_domain=0.882039, tgt_loss_domain=0.522355, loss=2.146573\n",
            "Epoch [   2/50] Step [350/468]: src_loss_class=0.703951, src_loss_domain=0.463435, tgt_loss_domain=0.734593, loss=1.901979\n",
            "Epoch [   2/50] Step [400/468]: src_loss_class=0.624485, src_loss_domain=0.576084, tgt_loss_domain=0.608511, loss=1.809081\n",
            "Epoch [   2/50] Step [450/468]: src_loss_class=0.855038, src_loss_domain=0.806363, tgt_loss_domain=0.396048, loss=2.057449\n",
            "Train SVHN score\n",
            "Avg Loss = 0.008152, Avg Accuracy = 66.86%, 48950.0/73216, Avg Domain Accuracy = 84.238418%\n",
            "Test SVHN score\n",
            "Avg Loss = 0.008021, Avg Accuracy = 67.17%, 17453.0/25984, Avg Domain Accuracy = 83.967057%\n",
            "Test MNIST score\n",
            "Avg Loss = 0.010519, Avg Accuracy = 62.08%, 6198.0/9984, Avg Domain Accuracy = 29.377003%\n",
            "Epoch [   3/50] Step [50/468]: src_loss_class=0.691682, src_loss_domain=0.799507, tgt_loss_domain=0.608463, loss=2.099652\n",
            "Epoch [   3/50] Step [100/468]: src_loss_class=0.613383, src_loss_domain=0.638230, tgt_loss_domain=0.677301, loss=1.928913\n",
            "Epoch [   3/50] Step [150/468]: src_loss_class=0.558018, src_loss_domain=0.646404, tgt_loss_domain=0.445711, loss=1.650133\n",
            "Epoch [   3/50] Step [200/468]: src_loss_class=0.601777, src_loss_domain=0.515801, tgt_loss_domain=0.795042, loss=1.912620\n",
            "Epoch [   3/50] Step [250/468]: src_loss_class=0.577752, src_loss_domain=0.533928, tgt_loss_domain=0.603023, loss=1.714704\n",
            "Epoch [   3/50] Step [300/468]: src_loss_class=0.399614, src_loss_domain=0.578853, tgt_loss_domain=0.753735, loss=1.732202\n",
            "Epoch [   3/50] Step [350/468]: src_loss_class=0.610830, src_loss_domain=0.604327, tgt_loss_domain=0.753422, loss=1.968579\n",
            "Epoch [   3/50] Step [400/468]: src_loss_class=0.546777, src_loss_domain=0.730644, tgt_loss_domain=0.581631, loss=1.859053\n",
            "Epoch [   3/50] Step [450/468]: src_loss_class=0.591144, src_loss_domain=0.641997, tgt_loss_domain=0.532476, loss=1.765618\n",
            "Train SVHN score\n",
            "Avg Loss = 0.004851, Avg Accuracy = 79.67%, 58331.0/73216, Avg Domain Accuracy = 73.542668%\n",
            "Test SVHN score\n",
            "Avg Loss = 0.004956, Avg Accuracy = 79.90%, 20760.0/25984, Avg Domain Accuracy = 71.482451%\n",
            "Test MNIST score\n",
            "Avg Loss = 0.013634, Avg Accuracy = 58.67%, 5858.0/9984, Avg Domain Accuracy = 36.288061%\n",
            "Epoch [   4/50] Step [50/468]: src_loss_class=0.563326, src_loss_domain=0.600022, tgt_loss_domain=0.697244, loss=1.860593\n",
            "Epoch [   4/50] Step [100/468]: src_loss_class=0.407176, src_loss_domain=0.864639, tgt_loss_domain=0.582877, loss=1.854693\n",
            "Epoch [   4/50] Step [150/468]: src_loss_class=0.550445, src_loss_domain=0.559846, tgt_loss_domain=0.604216, loss=1.714508\n",
            "Epoch [   4/50] Step [200/468]: src_loss_class=0.538167, src_loss_domain=0.488561, tgt_loss_domain=0.706981, loss=1.733709\n",
            "Epoch [   4/50] Step [250/468]: src_loss_class=0.520198, src_loss_domain=0.668258, tgt_loss_domain=0.618436, loss=1.806892\n",
            "Epoch [   4/50] Step [300/468]: src_loss_class=0.528659, src_loss_domain=0.536874, tgt_loss_domain=0.601049, loss=1.666582\n",
            "Epoch [   4/50] Step [350/468]: src_loss_class=0.582786, src_loss_domain=0.612484, tgt_loss_domain=0.705799, loss=1.901069\n",
            "Epoch [   4/50] Step [400/468]: src_loss_class=0.571872, src_loss_domain=0.643631, tgt_loss_domain=0.725338, loss=1.940842\n",
            "Epoch [   4/50] Step [450/468]: src_loss_class=0.501244, src_loss_domain=0.774544, tgt_loss_domain=0.702740, loss=1.978528\n",
            "Train SVHN score\n",
            "Avg Loss = 0.005890, Avg Accuracy = 75.20%, 55058.0/73216, Avg Domain Accuracy = 55.384069%\n",
            "Test SVHN score\n",
            "Avg Loss = 0.005758, Avg Accuracy = 75.92%, 19726.0/25984, Avg Domain Accuracy = 57.816349%\n",
            "Test MNIST score\n",
            "Avg Loss = 0.013164, Avg Accuracy = 63.22%, 6312.0/9984, Avg Domain Accuracy = 59.805689%\n",
            "Epoch [   5/50] Step [50/468]: src_loss_class=0.737097, src_loss_domain=0.790960, tgt_loss_domain=0.470319, loss=1.998376\n",
            "Epoch [   5/50] Step [100/468]: src_loss_class=0.616017, src_loss_domain=0.670559, tgt_loss_domain=0.718750, loss=2.005326\n",
            "Epoch [   5/50] Step [150/468]: src_loss_class=0.458797, src_loss_domain=0.575410, tgt_loss_domain=0.685827, loss=1.720034\n",
            "Epoch [   5/50] Step [200/468]: src_loss_class=0.383088, src_loss_domain=0.526809, tgt_loss_domain=0.686623, loss=1.596519\n",
            "Epoch [   5/50] Step [250/468]: src_loss_class=0.395030, src_loss_domain=0.611409, tgt_loss_domain=0.684693, loss=1.691133\n",
            "Epoch [   5/50] Step [300/468]: src_loss_class=0.653650, src_loss_domain=0.599740, tgt_loss_domain=0.682698, loss=1.936089\n",
            "Epoch [   5/50] Step [350/468]: src_loss_class=0.461264, src_loss_domain=0.620754, tgt_loss_domain=0.650809, loss=1.732828\n",
            "Epoch [   5/50] Step [400/468]: src_loss_class=0.526219, src_loss_domain=0.840186, tgt_loss_domain=0.598019, loss=1.964424\n",
            "Epoch [   5/50] Step [450/468]: src_loss_class=0.475003, src_loss_domain=0.588380, tgt_loss_domain=0.750316, loss=1.813698\n",
            "Train SVHN score\n",
            "Avg Loss = 0.004893, Avg Accuracy = 79.36%, 58102.0/73216, Avg Domain Accuracy = 63.181545%\n",
            "Test SVHN score\n",
            "Avg Loss = 0.005128, Avg Accuracy = 79.11%, 20556.0/25984, Avg Domain Accuracy = 63.723830%\n",
            "Test MNIST score\n",
            "Avg Loss = 0.011419, Avg Accuracy = 63.78%, 6368.0/9984, Avg Domain Accuracy = 57.271635%\n",
            "Epoch [   6/50] Step [50/468]: src_loss_class=0.378484, src_loss_domain=0.842548, tgt_loss_domain=0.608298, loss=1.829329\n",
            "Epoch [   6/50] Step [100/468]: src_loss_class=0.294459, src_loss_domain=0.700798, tgt_loss_domain=0.714567, loss=1.709824\n",
            "Epoch [   6/50] Step [150/468]: src_loss_class=0.374842, src_loss_domain=0.683768, tgt_loss_domain=0.656907, loss=1.715517\n",
            "Epoch [   6/50] Step [200/468]: src_loss_class=0.498407, src_loss_domain=0.689540, tgt_loss_domain=0.719833, loss=1.907780\n",
            "Epoch [   6/50] Step [250/468]: src_loss_class=0.618440, src_loss_domain=0.649551, tgt_loss_domain=0.620392, loss=1.888383\n",
            "Epoch [   6/50] Step [300/468]: src_loss_class=0.549357, src_loss_domain=0.551365, tgt_loss_domain=0.564495, loss=1.665217\n",
            "Epoch [   6/50] Step [350/468]: src_loss_class=0.571082, src_loss_domain=0.652696, tgt_loss_domain=0.779480, loss=2.003257\n",
            "Epoch [   6/50] Step [400/468]: src_loss_class=0.373147, src_loss_domain=0.705439, tgt_loss_domain=0.774367, loss=1.852953\n",
            "Epoch [   6/50] Step [450/468]: src_loss_class=0.331392, src_loss_domain=0.637854, tgt_loss_domain=0.692009, loss=1.661254\n",
            "Train SVHN score\n",
            "Avg Loss = 0.004685, Avg Accuracy = 81.03%, 59329.0/73216, Avg Domain Accuracy = 60.357026%\n",
            "Test SVHN score\n",
            "Avg Loss = 0.004858, Avg Accuracy = 80.67%, 20960.0/25984, Avg Domain Accuracy = 59.867611%\n",
            "Test MNIST score\n",
            "Avg Loss = 0.011919, Avg Accuracy = 63.61%, 6351.0/9984, Avg Domain Accuracy = 49.769631%\n",
            "Epoch [   7/50] Step [50/468]: src_loss_class=0.379171, src_loss_domain=0.778263, tgt_loss_domain=0.720157, loss=1.877591\n",
            "Epoch [   7/50] Step [100/468]: src_loss_class=0.567042, src_loss_domain=0.545132, tgt_loss_domain=0.785582, loss=1.897756\n",
            "Epoch [   7/50] Step [150/468]: src_loss_class=0.450901, src_loss_domain=0.691769, tgt_loss_domain=0.642509, loss=1.785179\n",
            "Epoch [   7/50] Step [200/468]: src_loss_class=0.492245, src_loss_domain=0.665475, tgt_loss_domain=0.574105, loss=1.731825\n",
            "Epoch [   7/50] Step [250/468]: src_loss_class=0.557630, src_loss_domain=0.653168, tgt_loss_domain=0.672528, loss=1.883325\n",
            "Epoch [   7/50] Step [300/468]: src_loss_class=0.456046, src_loss_domain=0.633636, tgt_loss_domain=0.690943, loss=1.780625\n",
            "Epoch [   7/50] Step [350/468]: src_loss_class=0.701482, src_loss_domain=0.594516, tgt_loss_domain=0.722322, loss=2.018320\n",
            "Epoch [   7/50] Step [400/468]: src_loss_class=0.285547, src_loss_domain=0.699316, tgt_loss_domain=0.522227, loss=1.507091\n",
            "Epoch [   7/50] Step [450/468]: src_loss_class=0.533983, src_loss_domain=0.626897, tgt_loss_domain=0.735158, loss=1.896038\n",
            "Train SVHN score\n",
            "Avg Loss = 0.006273, Avg Accuracy = 73.55%, 53848.0/73216, Avg Domain Accuracy = 49.206458%\n",
            "Test SVHN score\n",
            "Avg Loss = 0.006177, Avg Accuracy = 73.73%, 19159.0/25984, Avg Domain Accuracy = 48.787716%\n",
            "Test MNIST score\n",
            "Avg Loss = 0.011491, Avg Accuracy = 64.00%, 6390.0/9984, Avg Domain Accuracy = 40.715144%\n",
            "Epoch [   8/50] Step [50/468]: src_loss_class=0.358443, src_loss_domain=0.645447, tgt_loss_domain=0.596944, loss=1.600833\n",
            "Epoch [   8/50] Step [100/468]: src_loss_class=0.440208, src_loss_domain=0.646689, tgt_loss_domain=0.682426, loss=1.769323\n",
            "Epoch [   8/50] Step [150/468]: src_loss_class=0.388492, src_loss_domain=0.720559, tgt_loss_domain=0.700162, loss=1.809214\n",
            "Epoch [   8/50] Step [200/468]: src_loss_class=0.425777, src_loss_domain=0.787825, tgt_loss_domain=0.690246, loss=1.903848\n",
            "Epoch [   8/50] Step [250/468]: src_loss_class=0.447258, src_loss_domain=0.694748, tgt_loss_domain=0.678199, loss=1.820205\n",
            "Epoch [   8/50] Step [300/468]: src_loss_class=0.495339, src_loss_domain=0.718458, tgt_loss_domain=0.640678, loss=1.854475\n",
            "Epoch [   8/50] Step [350/468]: src_loss_class=0.434882, src_loss_domain=0.669511, tgt_loss_domain=0.692553, loss=1.796946\n",
            "Epoch [   8/50] Step [400/468]: src_loss_class=0.265534, src_loss_domain=0.606937, tgt_loss_domain=0.660714, loss=1.533186\n",
            "Epoch [   8/50] Step [450/468]: src_loss_class=0.452014, src_loss_domain=0.642594, tgt_loss_domain=0.720634, loss=1.815243\n",
            "Train SVHN score\n",
            "Avg Loss = 0.006618, Avg Accuracy = 73.76%, 54004.0/73216, Avg Domain Accuracy = 58.969351%\n",
            "Test SVHN score\n",
            "Avg Loss = 0.006487, Avg Accuracy = 73.92%, 19208.0/25984, Avg Domain Accuracy = 59.394243%\n",
            "Test MNIST score\n",
            "Avg Loss = 0.012261, Avg Accuracy = 64.78%, 6468.0/9984, Avg Domain Accuracy = 53.585737%\n",
            "Epoch [   9/50] Step [50/468]: src_loss_class=0.494511, src_loss_domain=0.676591, tgt_loss_domain=0.694881, loss=1.865983\n",
            "Epoch [   9/50] Step [100/468]: src_loss_class=0.436642, src_loss_domain=0.762189, tgt_loss_domain=0.550553, loss=1.749384\n",
            "Epoch [   9/50] Step [150/468]: src_loss_class=0.325156, src_loss_domain=0.628286, tgt_loss_domain=0.712488, loss=1.665930\n",
            "Epoch [   9/50] Step [200/468]: src_loss_class=0.472600, src_loss_domain=0.791072, tgt_loss_domain=0.691233, loss=1.954905\n",
            "Epoch [   9/50] Step [250/468]: src_loss_class=0.529930, src_loss_domain=0.749333, tgt_loss_domain=0.701686, loss=1.980950\n",
            "Epoch [   9/50] Step [300/468]: src_loss_class=0.590640, src_loss_domain=0.670779, tgt_loss_domain=0.616885, loss=1.878304\n",
            "Epoch [   9/50] Step [350/468]: src_loss_class=0.396359, src_loss_domain=0.735839, tgt_loss_domain=0.655084, loss=1.787283\n",
            "Epoch [   9/50] Step [400/468]: src_loss_class=0.330796, src_loss_domain=0.672973, tgt_loss_domain=0.688542, loss=1.692310\n",
            "Epoch [   9/50] Step [450/468]: src_loss_class=0.475396, src_loss_domain=0.663488, tgt_loss_domain=0.746827, loss=1.885711\n",
            "Train SVHN score\n",
            "Avg Loss = 0.004599, Avg Accuracy = 80.84%, 59188.0/73216, Avg Domain Accuracy = 55.423678%\n",
            "Test SVHN score\n",
            "Avg Loss = 0.004771, Avg Accuracy = 80.29%, 20863.0/25984, Avg Domain Accuracy = 56.030634%\n",
            "Test MNIST score\n",
            "Avg Loss = 0.011565, Avg Accuracy = 66.96%, 6685.0/9984, Avg Domain Accuracy = 53.385417%\n",
            "Epoch [  10/50] Step [50/468]: src_loss_class=0.350130, src_loss_domain=0.822924, tgt_loss_domain=0.701280, loss=1.874334\n",
            "Epoch [  10/50] Step [100/468]: src_loss_class=0.320246, src_loss_domain=0.731914, tgt_loss_domain=0.674910, loss=1.727070\n",
            "Epoch [  10/50] Step [150/468]: src_loss_class=0.486632, src_loss_domain=0.675460, tgt_loss_domain=0.668542, loss=1.830634\n",
            "Epoch [  10/50] Step [200/468]: src_loss_class=0.601509, src_loss_domain=0.599409, tgt_loss_domain=0.598704, loss=1.799621\n",
            "Epoch [  10/50] Step [250/468]: src_loss_class=0.571563, src_loss_domain=0.605287, tgt_loss_domain=0.758790, loss=1.935641\n",
            "Epoch [  10/50] Step [300/468]: src_loss_class=0.434772, src_loss_domain=0.644756, tgt_loss_domain=0.776165, loss=1.855693\n",
            "Epoch [  10/50] Step [350/468]: src_loss_class=0.443986, src_loss_domain=0.620340, tgt_loss_domain=0.717688, loss=1.782014\n",
            "Epoch [  10/50] Step [400/468]: src_loss_class=0.394460, src_loss_domain=0.741163, tgt_loss_domain=0.711275, loss=1.846898\n",
            "Epoch [  10/50] Step [450/468]: src_loss_class=0.590218, src_loss_domain=0.668823, tgt_loss_domain=0.685576, loss=1.944617\n",
            "Train SVHN score\n",
            "Avg Loss = 0.004437, Avg Accuracy = 81.41%, 59606.0/73216, Avg Domain Accuracy = 72.925317%\n",
            "Test SVHN score\n",
            "Avg Loss = 0.004779, Avg Accuracy = 80.08%, 20809.0/25984, Avg Domain Accuracy = 70.539563%\n",
            "Test MNIST score\n",
            "Avg Loss = 0.012426, Avg Accuracy = 65.97%, 6586.0/9984, Avg Domain Accuracy = 33.303285%\n",
            "Epoch [  11/50] Step [50/468]: src_loss_class=0.365901, src_loss_domain=0.668445, tgt_loss_domain=0.611966, loss=1.646312\n",
            "Epoch [  11/50] Step [100/468]: src_loss_class=0.302292, src_loss_domain=0.590276, tgt_loss_domain=0.677401, loss=1.569969\n",
            "Epoch [  11/50] Step [150/468]: src_loss_class=0.453370, src_loss_domain=0.702847, tgt_loss_domain=0.649255, loss=1.805471\n",
            "Epoch [  11/50] Step [200/468]: src_loss_class=0.316141, src_loss_domain=0.723955, tgt_loss_domain=0.617632, loss=1.657728\n",
            "Epoch [  11/50] Step [250/468]: src_loss_class=0.383685, src_loss_domain=0.668013, tgt_loss_domain=0.728920, loss=1.780618\n",
            "Epoch [  11/50] Step [300/468]: src_loss_class=0.484922, src_loss_domain=0.648144, tgt_loss_domain=0.790848, loss=1.923915\n",
            "Epoch [  11/50] Step [350/468]: src_loss_class=0.365444, src_loss_domain=0.832138, tgt_loss_domain=0.611399, loss=1.808981\n",
            "Epoch [  11/50] Step [400/468]: src_loss_class=0.424106, src_loss_domain=0.714691, tgt_loss_domain=0.622243, loss=1.761040\n",
            "Epoch [  11/50] Step [450/468]: src_loss_class=0.258096, src_loss_domain=0.711022, tgt_loss_domain=0.730188, loss=1.699306\n",
            "Train SVHN score\n",
            "Avg Loss = 0.004422, Avg Accuracy = 81.62%, 59762.0/73216, Avg Domain Accuracy = 73.314576%\n",
            "Test SVHN score\n",
            "Avg Loss = 0.004653, Avg Accuracy = 81.06%, 21063.0/25984, Avg Domain Accuracy = 72.198276%\n",
            "Test MNIST score\n",
            "Avg Loss = 0.013097, Avg Accuracy = 65.02%, 6492.0/9984, Avg Domain Accuracy = 28.114984%\n",
            "Epoch [  12/50] Step [50/468]: src_loss_class=0.423883, src_loss_domain=0.773034, tgt_loss_domain=0.709951, loss=1.906868\n",
            "Epoch [  12/50] Step [100/468]: src_loss_class=0.359090, src_loss_domain=0.669413, tgt_loss_domain=0.636752, loss=1.665256\n",
            "Epoch [  12/50] Step [150/468]: src_loss_class=0.273134, src_loss_domain=0.715620, tgt_loss_domain=0.669307, loss=1.658061\n",
            "Epoch [  12/50] Step [200/468]: src_loss_class=0.419355, src_loss_domain=0.634796, tgt_loss_domain=0.691763, loss=1.745914\n",
            "Epoch [  12/50] Step [250/468]: src_loss_class=0.468036, src_loss_domain=0.616839, tgt_loss_domain=0.767335, loss=1.852210\n",
            "Epoch [  12/50] Step [300/468]: src_loss_class=0.350007, src_loss_domain=0.608817, tgt_loss_domain=0.755054, loss=1.713878\n",
            "Epoch [  12/50] Step [350/468]: src_loss_class=0.321473, src_loss_domain=0.721996, tgt_loss_domain=0.660871, loss=1.704340\n",
            "Epoch [  12/50] Step [400/468]: src_loss_class=0.433738, src_loss_domain=0.655708, tgt_loss_domain=0.729152, loss=1.818599\n",
            "Epoch [  12/50] Step [450/468]: src_loss_class=0.442335, src_loss_domain=0.676780, tgt_loss_domain=0.680036, loss=1.799151\n",
            "Train SVHN score\n",
            "Avg Loss = 0.005827, Avg Accuracy = 75.86%, 55540.0/73216, Avg Domain Accuracy = 62.871503%\n",
            "Test SVHN score\n",
            "Avg Loss = 0.005880, Avg Accuracy = 75.71%, 19673.0/25984, Avg Domain Accuracy = 62.669335%\n",
            "Test MNIST score\n",
            "Avg Loss = 0.010444, Avg Accuracy = 68.31%, 6820.0/9984, Avg Domain Accuracy = 43.309295%\n",
            "Epoch [  13/50] Step [50/468]: src_loss_class=0.526284, src_loss_domain=0.682666, tgt_loss_domain=0.609581, loss=1.818531\n",
            "Epoch [  13/50] Step [100/468]: src_loss_class=0.347788, src_loss_domain=0.586899, tgt_loss_domain=0.664190, loss=1.598878\n",
            "Epoch [  13/50] Step [150/468]: src_loss_class=0.661702, src_loss_domain=0.664041, tgt_loss_domain=0.683819, loss=2.009562\n",
            "Epoch [  13/50] Step [200/468]: src_loss_class=0.554480, src_loss_domain=0.653159, tgt_loss_domain=0.729252, loss=1.936890\n",
            "Epoch [  13/50] Step [250/468]: src_loss_class=0.351198, src_loss_domain=0.665451, tgt_loss_domain=0.715451, loss=1.732101\n",
            "Epoch [  13/50] Step [300/468]: src_loss_class=0.406698, src_loss_domain=0.728474, tgt_loss_domain=0.700029, loss=1.835202\n",
            "Epoch [  13/50] Step [350/468]: src_loss_class=0.331947, src_loss_domain=0.722035, tgt_loss_domain=0.713501, loss=1.767482\n",
            "Epoch [  13/50] Step [400/468]: src_loss_class=0.425158, src_loss_domain=0.716020, tgt_loss_domain=0.576568, loss=1.717746\n",
            "Epoch [  13/50] Step [450/468]: src_loss_class=0.364785, src_loss_domain=0.700031, tgt_loss_domain=0.666907, loss=1.731724\n",
            "Train SVHN score\n",
            "Avg Loss = 0.003725, Avg Accuracy = 84.56%, 61914.0/73216, Avg Domain Accuracy = 65.366860%\n",
            "Test SVHN score\n",
            "Avg Loss = 0.004011, Avg Accuracy = 83.61%, 21726.0/25984, Avg Domain Accuracy = 63.161946%\n",
            "Test MNIST score\n",
            "Avg Loss = 0.011878, Avg Accuracy = 66.47%, 6636.0/9984, Avg Domain Accuracy = 56.700721%\n",
            "Epoch [  14/50] Step [50/468]: src_loss_class=0.430777, src_loss_domain=0.656634, tgt_loss_domain=0.697010, loss=1.784421\n",
            "Epoch [  14/50] Step [100/468]: src_loss_class=0.379088, src_loss_domain=0.675374, tgt_loss_domain=0.732697, loss=1.787159\n",
            "Epoch [  14/50] Step [150/468]: src_loss_class=0.421794, src_loss_domain=0.656688, tgt_loss_domain=0.650654, loss=1.729135\n",
            "Epoch [  14/50] Step [200/468]: src_loss_class=0.374151, src_loss_domain=0.654769, tgt_loss_domain=0.725549, loss=1.754469\n",
            "Epoch [  14/50] Step [250/468]: src_loss_class=0.274371, src_loss_domain=0.663691, tgt_loss_domain=0.713405, loss=1.651468\n",
            "Epoch [  14/50] Step [300/468]: src_loss_class=0.293911, src_loss_domain=0.661270, tgt_loss_domain=0.662862, loss=1.618043\n",
            "Epoch [  14/50] Step [350/468]: src_loss_class=0.425644, src_loss_domain=0.614266, tgt_loss_domain=0.680573, loss=1.720483\n",
            "Epoch [  14/50] Step [400/468]: src_loss_class=0.307229, src_loss_domain=0.695473, tgt_loss_domain=0.683491, loss=1.686193\n",
            "Epoch [  14/50] Step [450/468]: src_loss_class=0.269008, src_loss_domain=0.667007, tgt_loss_domain=0.686500, loss=1.622515\n",
            "Train SVHN score\n",
            "Avg Loss = 0.003802, Avg Accuracy = 84.51%, 61876.0/73216, Avg Domain Accuracy = 66.597465%\n",
            "Test SVHN score\n",
            "Avg Loss = 0.004172, Avg Accuracy = 83.30%, 21644.0/25984, Avg Domain Accuracy = 64.224138%\n",
            "Test MNIST score\n",
            "Avg Loss = 0.010623, Avg Accuracy = 70.27%, 7016.0/9984, Avg Domain Accuracy = 43.920272%\n",
            "Epoch [  15/50] Step [50/468]: src_loss_class=0.483883, src_loss_domain=0.638207, tgt_loss_domain=0.669508, loss=1.791598\n",
            "Epoch [  15/50] Step [100/468]: src_loss_class=0.290568, src_loss_domain=0.649702, tgt_loss_domain=0.619529, loss=1.559798\n",
            "Epoch [  15/50] Step [150/468]: src_loss_class=0.327110, src_loss_domain=0.650505, tgt_loss_domain=0.753594, loss=1.731209\n",
            "Epoch [  15/50] Step [200/468]: src_loss_class=0.385054, src_loss_domain=0.630333, tgt_loss_domain=0.734725, loss=1.750112\n",
            "Epoch [  15/50] Step [250/468]: src_loss_class=0.615839, src_loss_domain=0.659080, tgt_loss_domain=0.700860, loss=1.975778\n",
            "Epoch [  15/50] Step [300/468]: src_loss_class=0.432824, src_loss_domain=0.602917, tgt_loss_domain=0.758908, loss=1.794650\n",
            "Epoch [  15/50] Step [350/468]: src_loss_class=0.251584, src_loss_domain=0.706508, tgt_loss_domain=0.616979, loss=1.575071\n",
            "Epoch [  15/50] Step [400/468]: src_loss_class=0.536025, src_loss_domain=0.757426, tgt_loss_domain=0.662282, loss=1.955733\n",
            "Epoch [  15/50] Step [450/468]: src_loss_class=0.294693, src_loss_domain=0.673322, tgt_loss_domain=0.675497, loss=1.643512\n",
            "Train SVHN score\n",
            "Avg Loss = 0.004745, Avg Accuracy = 80.06%, 58620.0/73216, Avg Domain Accuracy = 62.723995%\n",
            "Test SVHN score\n",
            "Avg Loss = 0.004824, Avg Accuracy = 79.93%, 20769.0/25984, Avg Domain Accuracy = 59.394243%\n",
            "Test MNIST score\n",
            "Avg Loss = 0.012561, Avg Accuracy = 67.86%, 6775.0/9984, Avg Domain Accuracy = 52.774439%\n",
            "Epoch [  16/50] Step [50/468]: src_loss_class=0.266696, src_loss_domain=0.643414, tgt_loss_domain=0.671387, loss=1.581497\n",
            "Epoch [  16/50] Step [100/468]: src_loss_class=0.359987, src_loss_domain=0.692660, tgt_loss_domain=0.649704, loss=1.702351\n",
            "Epoch [  16/50] Step [150/468]: src_loss_class=0.495345, src_loss_domain=0.681083, tgt_loss_domain=0.668942, loss=1.845369\n",
            "Epoch [  16/50] Step [200/468]: src_loss_class=0.426216, src_loss_domain=0.623589, tgt_loss_domain=0.741416, loss=1.791222\n",
            "Epoch [  16/50] Step [250/468]: src_loss_class=0.429195, src_loss_domain=0.669064, tgt_loss_domain=0.659262, loss=1.757521\n",
            "Epoch [  16/50] Step [300/468]: src_loss_class=0.300942, src_loss_domain=0.707712, tgt_loss_domain=0.600695, loss=1.609349\n",
            "Epoch [  16/50] Step [350/468]: src_loss_class=0.455531, src_loss_domain=0.725004, tgt_loss_domain=0.662991, loss=1.843526\n",
            "Epoch [  16/50] Step [400/468]: src_loss_class=0.356190, src_loss_domain=0.790708, tgt_loss_domain=0.725053, loss=1.871951\n",
            "Epoch [  16/50] Step [450/468]: src_loss_class=0.343953, src_loss_domain=0.668959, tgt_loss_domain=0.705135, loss=1.718048\n",
            "Train SVHN score\n",
            "Avg Loss = 0.004134, Avg Accuracy = 82.60%, 60476.0/73216, Avg Domain Accuracy = 33.321951%\n",
            "Test SVHN score\n",
            "Avg Loss = 0.004378, Avg Accuracy = 82.32%, 21391.0/25984, Avg Domain Accuracy = 31.523245%\n",
            "Test MNIST score\n",
            "Avg Loss = 0.011073, Avg Accuracy = 68.58%, 6847.0/9984, Avg Domain Accuracy = 65.034054%\n",
            "Epoch [  17/50] Step [50/468]: src_loss_class=0.326479, src_loss_domain=0.641358, tgt_loss_domain=0.703256, loss=1.671093\n",
            "Epoch [  17/50] Step [100/468]: src_loss_class=0.342634, src_loss_domain=0.725498, tgt_loss_domain=0.689479, loss=1.757612\n",
            "Epoch [  17/50] Step [150/468]: src_loss_class=0.421262, src_loss_domain=0.590739, tgt_loss_domain=0.702455, loss=1.714456\n",
            "Epoch [  17/50] Step [200/468]: src_loss_class=0.231080, src_loss_domain=0.581742, tgt_loss_domain=0.752632, loss=1.565455\n",
            "Epoch [  17/50] Step [250/468]: src_loss_class=0.442660, src_loss_domain=0.590837, tgt_loss_domain=0.740522, loss=1.774019\n",
            "Epoch [  17/50] Step [300/468]: src_loss_class=0.286860, src_loss_domain=0.721755, tgt_loss_domain=0.725016, loss=1.733631\n",
            "Epoch [  17/50] Step [350/468]: src_loss_class=0.348336, src_loss_domain=0.673872, tgt_loss_domain=0.663299, loss=1.685506\n",
            "Epoch [  17/50] Step [400/468]: src_loss_class=0.373429, src_loss_domain=0.620427, tgt_loss_domain=0.661143, loss=1.654999\n",
            "Epoch [  17/50] Step [450/468]: src_loss_class=0.255810, src_loss_domain=0.809749, tgt_loss_domain=0.673533, loss=1.739093\n",
            "Train SVHN score\n",
            "Avg Loss = 0.003664, Avg Accuracy = 84.97%, 62214.0/73216, Avg Domain Accuracy = 72.452743%\n",
            "Test SVHN score\n",
            "Avg Loss = 0.003882, Avg Accuracy = 84.54%, 21968.0/25984, Avg Domain Accuracy = 72.867919%\n",
            "Test MNIST score\n",
            "Avg Loss = 0.012562, Avg Accuracy = 66.70%, 6659.0/9984, Avg Domain Accuracy = 39.503205%\n",
            "Epoch [  18/50] Step [50/468]: src_loss_class=0.303086, src_loss_domain=0.628864, tgt_loss_domain=0.780716, loss=1.712666\n",
            "Epoch [  18/50] Step [100/468]: src_loss_class=0.511896, src_loss_domain=0.730743, tgt_loss_domain=0.694344, loss=1.936983\n",
            "Epoch [  18/50] Step [150/468]: src_loss_class=0.367693, src_loss_domain=0.656930, tgt_loss_domain=0.671664, loss=1.696288\n",
            "Epoch [  18/50] Step [200/468]: src_loss_class=0.350783, src_loss_domain=0.636034, tgt_loss_domain=0.767397, loss=1.754214\n",
            "Epoch [  18/50] Step [250/468]: src_loss_class=0.406755, src_loss_domain=0.707614, tgt_loss_domain=0.625931, loss=1.740300\n",
            "Epoch [  18/50] Step [300/468]: src_loss_class=0.293059, src_loss_domain=0.715061, tgt_loss_domain=0.715820, loss=1.723939\n",
            "Epoch [  18/50] Step [350/468]: src_loss_class=0.247145, src_loss_domain=0.673282, tgt_loss_domain=0.663633, loss=1.584059\n",
            "Epoch [  18/50] Step [400/468]: src_loss_class=0.338349, src_loss_domain=0.707818, tgt_loss_domain=0.627753, loss=1.673920\n",
            "Epoch [  18/50] Step [450/468]: src_loss_class=0.250728, src_loss_domain=0.609962, tgt_loss_domain=0.695855, loss=1.556545\n",
            "Train SVHN score\n",
            "Avg Loss = 0.003793, Avg Accuracy = 84.26%, 61689.0/73216, Avg Domain Accuracy = 49.648984%\n",
            "Test SVHN score\n",
            "Avg Loss = 0.004006, Avg Accuracy = 83.97%, 21820.0/25984, Avg Domain Accuracy = 46.555573%\n",
            "Test MNIST score\n",
            "Avg Loss = 0.010271, Avg Accuracy = 70.76%, 7065.0/9984, Avg Domain Accuracy = 69.661458%\n",
            "Epoch [  19/50] Step [50/468]: src_loss_class=0.343198, src_loss_domain=0.731999, tgt_loss_domain=0.606665, loss=1.681861\n",
            "Epoch [  19/50] Step [100/468]: src_loss_class=0.632168, src_loss_domain=0.723765, tgt_loss_domain=0.605321, loss=1.961254\n",
            "Epoch [  19/50] Step [150/468]: src_loss_class=0.371897, src_loss_domain=0.706868, tgt_loss_domain=0.638073, loss=1.716838\n",
            "Epoch [  19/50] Step [200/468]: src_loss_class=0.281085, src_loss_domain=0.641827, tgt_loss_domain=0.693188, loss=1.616101\n",
            "Epoch [  19/50] Step [250/468]: src_loss_class=0.329064, src_loss_domain=0.708588, tgt_loss_domain=0.597572, loss=1.635224\n",
            "Epoch [  19/50] Step [300/468]: src_loss_class=0.335375, src_loss_domain=0.693351, tgt_loss_domain=0.677466, loss=1.706192\n",
            "Epoch [  19/50] Step [350/468]: src_loss_class=0.195739, src_loss_domain=0.642410, tgt_loss_domain=0.750580, loss=1.588729\n",
            "Epoch [  19/50] Step [400/468]: src_loss_class=0.282041, src_loss_domain=0.676673, tgt_loss_domain=0.695076, loss=1.653790\n",
            "Epoch [  19/50] Step [450/468]: src_loss_class=0.378232, src_loss_domain=0.718654, tgt_loss_domain=0.603086, loss=1.699973\n",
            "Train SVHN score\n",
            "Avg Loss = 0.003459, Avg Accuracy = 86.22%, 63124.0/73216, Avg Domain Accuracy = 75.689740%\n",
            "Test SVHN score\n",
            "Avg Loss = 0.003815, Avg Accuracy = 85.39%, 22187.0/25984, Avg Domain Accuracy = 75.708128%\n",
            "Test MNIST score\n",
            "Avg Loss = 0.011471, Avg Accuracy = 68.99%, 6888.0/9984, Avg Domain Accuracy = 39.312901%\n",
            "Epoch [  20/50] Step [50/468]: src_loss_class=0.297449, src_loss_domain=0.758270, tgt_loss_domain=0.650885, loss=1.706604\n",
            "Epoch [  20/50] Step [100/468]: src_loss_class=0.248697, src_loss_domain=0.647541, tgt_loss_domain=0.629536, loss=1.525774\n",
            "Epoch [  20/50] Step [150/468]: src_loss_class=0.400744, src_loss_domain=0.608489, tgt_loss_domain=0.758737, loss=1.767970\n",
            "Epoch [  20/50] Step [200/468]: src_loss_class=0.345957, src_loss_domain=0.683147, tgt_loss_domain=0.669773, loss=1.698877\n",
            "Epoch [  20/50] Step [250/468]: src_loss_class=0.402143, src_loss_domain=0.725954, tgt_loss_domain=0.663549, loss=1.791645\n",
            "Epoch [  20/50] Step [300/468]: src_loss_class=0.300496, src_loss_domain=0.717852, tgt_loss_domain=0.660528, loss=1.678876\n",
            "Epoch [  20/50] Step [350/468]: src_loss_class=0.448152, src_loss_domain=0.734864, tgt_loss_domain=0.766950, loss=1.949966\n",
            "Epoch [  20/50] Step [400/468]: src_loss_class=0.310692, src_loss_domain=0.654226, tgt_loss_domain=0.699578, loss=1.664496\n",
            "Epoch [  20/50] Step [450/468]: src_loss_class=0.376542, src_loss_domain=0.667052, tgt_loss_domain=0.705432, loss=1.749025\n",
            "Train SVHN score\n",
            "Avg Loss = 0.003398, Avg Accuracy = 86.49%, 63325.0/73216, Avg Domain Accuracy = 49.953562%\n",
            "Test SVHN score\n",
            "Avg Loss = 0.003717, Avg Accuracy = 85.65%, 22255.0/25984, Avg Domain Accuracy = 47.725523%\n",
            "Test MNIST score\n",
            "Avg Loss = 0.010701, Avg Accuracy = 69.34%, 6923.0/9984, Avg Domain Accuracy = 54.216747%\n",
            "Epoch [  21/50] Step [50/468]: src_loss_class=0.414032, src_loss_domain=0.651039, tgt_loss_domain=0.704599, loss=1.769670\n",
            "Epoch [  21/50] Step [100/468]: src_loss_class=0.344099, src_loss_domain=0.691481, tgt_loss_domain=0.655465, loss=1.691045\n",
            "Epoch [  21/50] Step [150/468]: src_loss_class=0.335834, src_loss_domain=0.695326, tgt_loss_domain=0.657941, loss=1.689101\n",
            "Epoch [  21/50] Step [200/468]: src_loss_class=0.210737, src_loss_domain=0.554773, tgt_loss_domain=0.790775, loss=1.556284\n",
            "Epoch [  21/50] Step [250/468]: src_loss_class=0.563016, src_loss_domain=0.647547, tgt_loss_domain=0.674780, loss=1.885343\n",
            "Epoch [  21/50] Step [300/468]: src_loss_class=0.271191, src_loss_domain=0.645712, tgt_loss_domain=0.758249, loss=1.675152\n",
            "Epoch [  21/50] Step [350/468]: src_loss_class=0.459327, src_loss_domain=0.673311, tgt_loss_domain=0.727803, loss=1.860441\n",
            "Epoch [  21/50] Step [400/468]: src_loss_class=0.354898, src_loss_domain=0.715403, tgt_loss_domain=0.672757, loss=1.743058\n",
            "Epoch [  21/50] Step [450/468]: src_loss_class=0.322968, src_loss_domain=0.722774, tgt_loss_domain=0.691231, loss=1.736974\n",
            "Train SVHN score\n",
            "Avg Loss = 0.003473, Avg Accuracy = 86.23%, 63132.0/73216, Avg Domain Accuracy = 61.983719%\n",
            "Test SVHN score\n",
            "Avg Loss = 0.003886, Avg Accuracy = 84.82%, 22040.0/25984, Avg Domain Accuracy = 61.834206%\n",
            "Test MNIST score\n",
            "Avg Loss = 0.012048, Avg Accuracy = 68.68%, 6857.0/9984, Avg Domain Accuracy = 45.993590%\n",
            "Epoch [  22/50] Step [50/468]: src_loss_class=0.323910, src_loss_domain=0.626015, tgt_loss_domain=0.724476, loss=1.674401\n",
            "Epoch [  22/50] Step [100/468]: src_loss_class=0.354293, src_loss_domain=0.718239, tgt_loss_domain=0.689840, loss=1.762372\n",
            "Epoch [  22/50] Step [150/468]: src_loss_class=0.329033, src_loss_domain=0.717941, tgt_loss_domain=0.629954, loss=1.676928\n",
            "Epoch [  22/50] Step [200/468]: src_loss_class=0.611926, src_loss_domain=0.706925, tgt_loss_domain=0.652803, loss=1.971654\n",
            "Epoch [  22/50] Step [250/468]: src_loss_class=0.382356, src_loss_domain=0.693191, tgt_loss_domain=0.670774, loss=1.746321\n",
            "Epoch [  22/50] Step [300/468]: src_loss_class=0.236743, src_loss_domain=0.702220, tgt_loss_domain=0.585736, loss=1.524699\n",
            "Epoch [  22/50] Step [350/468]: src_loss_class=0.498095, src_loss_domain=0.641696, tgt_loss_domain=0.675932, loss=1.815724\n",
            "Epoch [  22/50] Step [400/468]: src_loss_class=0.371801, src_loss_domain=0.722438, tgt_loss_domain=0.633526, loss=1.727765\n",
            "Epoch [  22/50] Step [450/468]: src_loss_class=0.436013, src_loss_domain=0.680001, tgt_loss_domain=0.714110, loss=1.830124\n",
            "Train SVHN score\n",
            "Avg Loss = 0.003535, Avg Accuracy = 85.48%, 62586.0/73216, Avg Domain Accuracy = 60.393903%\n",
            "Test SVHN score\n",
            "Avg Loss = 0.003866, Avg Accuracy = 84.31%, 21906.0/25984, Avg Domain Accuracy = 59.036330%\n",
            "Test MNIST score\n",
            "Avg Loss = 0.012291, Avg Accuracy = 68.93%, 6882.0/9984, Avg Domain Accuracy = 58.483574%\n",
            "Epoch [  23/50] Step [50/468]: src_loss_class=0.334392, src_loss_domain=0.692005, tgt_loss_domain=0.703018, loss=1.729415\n",
            "Epoch [  23/50] Step [100/468]: src_loss_class=0.366318, src_loss_domain=0.689035, tgt_loss_domain=0.650394, loss=1.705747\n",
            "Epoch [  23/50] Step [150/468]: src_loss_class=0.226362, src_loss_domain=0.683770, tgt_loss_domain=0.686065, loss=1.596197\n",
            "Epoch [  23/50] Step [200/468]: src_loss_class=0.318544, src_loss_domain=0.697801, tgt_loss_domain=0.676670, loss=1.693015\n",
            "Epoch [  23/50] Step [250/468]: src_loss_class=0.454585, src_loss_domain=0.728148, tgt_loss_domain=0.708674, loss=1.891407\n",
            "Epoch [  23/50] Step [300/468]: src_loss_class=0.405521, src_loss_domain=0.689146, tgt_loss_domain=0.635909, loss=1.730576\n",
            "Epoch [  23/50] Step [350/468]: src_loss_class=0.365453, src_loss_domain=0.689393, tgt_loss_domain=0.687684, loss=1.742530\n",
            "Epoch [  23/50] Step [400/468]: src_loss_class=0.203455, src_loss_domain=0.667256, tgt_loss_domain=0.763366, loss=1.634077\n",
            "Epoch [  23/50] Step [450/468]: src_loss_class=0.326143, src_loss_domain=0.645303, tgt_loss_domain=0.649277, loss=1.620723\n",
            "Train SVHN score\n",
            "Avg Loss = 0.003408, Avg Accuracy = 86.39%, 63252.0/73216, Avg Domain Accuracy = 54.135708%\n",
            "Test SVHN score\n",
            "Avg Loss = 0.003791, Avg Accuracy = 85.16%, 22128.0/25984, Avg Domain Accuracy = 52.674723%\n",
            "Test MNIST score\n",
            "Avg Loss = 0.010901, Avg Accuracy = 70.74%, 7063.0/9984, Avg Domain Accuracy = 59.405048%\n",
            "Epoch [  24/50] Step [50/468]: src_loss_class=0.384716, src_loss_domain=0.640519, tgt_loss_domain=0.768931, loss=1.794166\n",
            "Epoch [  24/50] Step [100/468]: src_loss_class=0.331562, src_loss_domain=0.678144, tgt_loss_domain=0.709197, loss=1.718903\n",
            "Epoch [  24/50] Step [150/468]: src_loss_class=0.171219, src_loss_domain=0.620498, tgt_loss_domain=0.702835, loss=1.494552\n",
            "Epoch [  24/50] Step [200/468]: src_loss_class=0.305492, src_loss_domain=0.705535, tgt_loss_domain=0.685113, loss=1.696141\n",
            "Epoch [  24/50] Step [250/468]: src_loss_class=0.278901, src_loss_domain=0.700495, tgt_loss_domain=0.687625, loss=1.667022\n",
            "Epoch [  24/50] Step [300/468]: src_loss_class=0.354291, src_loss_domain=0.651027, tgt_loss_domain=0.709076, loss=1.714395\n",
            "Epoch [  24/50] Step [350/468]: src_loss_class=0.265076, src_loss_domain=0.633999, tgt_loss_domain=0.750029, loss=1.649103\n",
            "Epoch [  24/50] Step [400/468]: src_loss_class=0.255519, src_loss_domain=0.741891, tgt_loss_domain=0.657350, loss=1.654761\n",
            "Epoch [  24/50] Step [450/468]: src_loss_class=0.274914, src_loss_domain=0.680081, tgt_loss_domain=0.679658, loss=1.634653\n",
            "Train SVHN score\n",
            "Avg Loss = 0.003312, Avg Accuracy = 86.86%, 63594.0/73216, Avg Domain Accuracy = 53.321678%\n",
            "Test SVHN score\n",
            "Avg Loss = 0.003675, Avg Accuracy = 85.79%, 22292.0/25984, Avg Domain Accuracy = 50.885160%\n",
            "Test MNIST score\n",
            "Avg Loss = 0.013142, Avg Accuracy = 68.73%, 6862.0/9984, Avg Domain Accuracy = 57.972756%\n",
            "Epoch [  25/50] Step [50/468]: src_loss_class=0.254090, src_loss_domain=0.622538, tgt_loss_domain=0.623768, loss=1.500396\n",
            "Epoch [  25/50] Step [100/468]: src_loss_class=0.394977, src_loss_domain=0.706987, tgt_loss_domain=0.661906, loss=1.763870\n",
            "Epoch [  25/50] Step [150/468]: src_loss_class=0.253649, src_loss_domain=0.689690, tgt_loss_domain=0.631680, loss=1.575019\n",
            "Epoch [  25/50] Step [200/468]: src_loss_class=0.285350, src_loss_domain=0.671475, tgt_loss_domain=0.668323, loss=1.625148\n",
            "Epoch [  25/50] Step [250/468]: src_loss_class=0.240470, src_loss_domain=0.649724, tgt_loss_domain=0.735173, loss=1.625367\n",
            "Epoch [  25/50] Step [300/468]: src_loss_class=0.287160, src_loss_domain=0.628024, tgt_loss_domain=0.667548, loss=1.582731\n",
            "Epoch [  25/50] Step [350/468]: src_loss_class=0.402766, src_loss_domain=0.709771, tgt_loss_domain=0.634658, loss=1.747195\n",
            "Epoch [  25/50] Step [400/468]: src_loss_class=0.195429, src_loss_domain=0.681048, tgt_loss_domain=0.675759, loss=1.552235\n",
            "Epoch [  25/50] Step [450/468]: src_loss_class=0.421235, src_loss_domain=0.692722, tgt_loss_domain=0.664122, loss=1.778079\n",
            "Train SVHN score\n",
            "Avg Loss = 0.003655, Avg Accuracy = 84.79%, 62080.0/73216, Avg Domain Accuracy = 58.321951%\n",
            "Test SVHN score\n",
            "Avg Loss = 0.004065, Avg Accuracy = 83.51%, 21700.0/25984, Avg Domain Accuracy = 59.829126%\n",
            "Test MNIST score\n",
            "Avg Loss = 0.010091, Avg Accuracy = 69.93%, 6982.0/9984, Avg Domain Accuracy = 38.912260%\n",
            "Epoch [  26/50] Step [50/468]: src_loss_class=0.260159, src_loss_domain=0.723129, tgt_loss_domain=0.650548, loss=1.633836\n",
            "Epoch [  26/50] Step [100/468]: src_loss_class=0.275896, src_loss_domain=0.708551, tgt_loss_domain=0.626700, loss=1.611147\n",
            "Epoch [  26/50] Step [150/468]: src_loss_class=0.398021, src_loss_domain=0.682483, tgt_loss_domain=0.689378, loss=1.769881\n",
            "Epoch [  26/50] Step [200/468]: src_loss_class=0.325130, src_loss_domain=0.707719, tgt_loss_domain=0.696694, loss=1.729543\n",
            "Epoch [  26/50] Step [250/468]: src_loss_class=0.257073, src_loss_domain=0.677591, tgt_loss_domain=0.669928, loss=1.604593\n",
            "Epoch [  26/50] Step [300/468]: src_loss_class=0.358123, src_loss_domain=0.651055, tgt_loss_domain=0.702529, loss=1.711707\n",
            "Epoch [  26/50] Step [350/468]: src_loss_class=0.440001, src_loss_domain=0.751974, tgt_loss_domain=0.581544, loss=1.773518\n",
            "Epoch [  26/50] Step [400/468]: src_loss_class=0.251408, src_loss_domain=0.746456, tgt_loss_domain=0.675734, loss=1.673599\n",
            "Epoch [  26/50] Step [450/468]: src_loss_class=0.203423, src_loss_domain=0.718971, tgt_loss_domain=0.649017, loss=1.571411\n",
            "Train SVHN score\n",
            "Avg Loss = 0.003424, Avg Accuracy = 86.03%, 62989.0/73216, Avg Domain Accuracy = 61.427830%\n",
            "Test SVHN score\n",
            "Avg Loss = 0.003879, Avg Accuracy = 84.69%, 22006.0/25984, Avg Domain Accuracy = 60.979834%\n",
            "Test MNIST score\n",
            "Avg Loss = 0.011746, Avg Accuracy = 69.25%, 6914.0/9984, Avg Domain Accuracy = 36.868990%\n",
            "Epoch [  27/50] Step [50/468]: src_loss_class=0.305005, src_loss_domain=0.683210, tgt_loss_domain=0.714541, loss=1.702757\n",
            "Epoch [  27/50] Step [100/468]: src_loss_class=0.368354, src_loss_domain=0.684216, tgt_loss_domain=0.694756, loss=1.747326\n",
            "Epoch [  27/50] Step [150/468]: src_loss_class=0.255770, src_loss_domain=0.657560, tgt_loss_domain=0.710327, loss=1.623658\n",
            "Epoch [  27/50] Step [200/468]: src_loss_class=0.233299, src_loss_domain=0.676152, tgt_loss_domain=0.623382, loss=1.532833\n",
            "Epoch [  27/50] Step [250/468]: src_loss_class=0.272619, src_loss_domain=0.654878, tgt_loss_domain=0.681333, loss=1.608830\n",
            "Epoch [  27/50] Step [300/468]: src_loss_class=0.249950, src_loss_domain=0.656083, tgt_loss_domain=0.699929, loss=1.605962\n",
            "Epoch [  27/50] Step [350/468]: src_loss_class=0.547609, src_loss_domain=0.714822, tgt_loss_domain=0.661423, loss=1.923855\n",
            "Epoch [  27/50] Step [400/468]: src_loss_class=0.202284, src_loss_domain=0.641465, tgt_loss_domain=0.723439, loss=1.567188\n",
            "Epoch [  27/50] Step [450/468]: src_loss_class=0.279780, src_loss_domain=0.654509, tgt_loss_domain=0.728433, loss=1.662723\n",
            "Train SVHN score\n",
            "Avg Loss = 0.003181, Avg Accuracy = 86.87%, 63605.0/73216, Avg Domain Accuracy = 48.766663%\n",
            "Test SVHN score\n",
            "Avg Loss = 0.003564, Avg Accuracy = 85.75%, 22281.0/25984, Avg Domain Accuracy = 49.134083%\n",
            "Test MNIST score\n",
            "Avg Loss = 0.010847, Avg Accuracy = 68.98%, 6887.0/9984, Avg Domain Accuracy = 60.276442%\n",
            "Epoch [  28/50] Step [50/468]: src_loss_class=0.386708, src_loss_domain=0.670393, tgt_loss_domain=0.655094, loss=1.712195\n",
            "Epoch [  28/50] Step [100/468]: src_loss_class=0.234055, src_loss_domain=0.574581, tgt_loss_domain=0.754358, loss=1.562994\n",
            "Epoch [  28/50] Step [150/468]: src_loss_class=0.262588, src_loss_domain=0.650652, tgt_loss_domain=0.675534, loss=1.588774\n",
            "Epoch [  28/50] Step [200/468]: src_loss_class=0.344810, src_loss_domain=0.631203, tgt_loss_domain=0.709792, loss=1.685805\n",
            "Epoch [  28/50] Step [250/468]: src_loss_class=0.402392, src_loss_domain=0.661197, tgt_loss_domain=0.703584, loss=1.767173\n",
            "Epoch [  28/50] Step [300/468]: src_loss_class=0.419149, src_loss_domain=0.650016, tgt_loss_domain=0.704840, loss=1.774005\n",
            "Epoch [  28/50] Step [350/468]: src_loss_class=0.350401, src_loss_domain=0.695035, tgt_loss_domain=0.682229, loss=1.727665\n",
            "Epoch [  28/50] Step [400/468]: src_loss_class=0.367532, src_loss_domain=0.674556, tgt_loss_domain=0.698325, loss=1.740412\n",
            "Epoch [  28/50] Step [450/468]: src_loss_class=0.271015, src_loss_domain=0.590929, tgt_loss_domain=0.741944, loss=1.603889\n",
            "Train SVHN score\n",
            "Avg Loss = 0.003523, Avg Accuracy = 85.18%, 62362.0/73216, Avg Domain Accuracy = 57.087249%\n",
            "Test SVHN score\n",
            "Avg Loss = 0.003853, Avg Accuracy = 84.39%, 21927.0/25984, Avg Domain Accuracy = 56.161484%\n",
            "Test MNIST score\n",
            "Avg Loss = 0.009878, Avg Accuracy = 70.91%, 7080.0/9984, Avg Domain Accuracy = 64.883814%\n",
            "Epoch [  29/50] Step [50/468]: src_loss_class=0.320935, src_loss_domain=0.705861, tgt_loss_domain=0.688569, loss=1.715365\n",
            "Epoch [  29/50] Step [100/468]: src_loss_class=0.378451, src_loss_domain=0.714070, tgt_loss_domain=0.678397, loss=1.770918\n",
            "Epoch [  29/50] Step [150/468]: src_loss_class=0.341415, src_loss_domain=0.680717, tgt_loss_domain=0.655041, loss=1.677174\n",
            "Epoch [  29/50] Step [200/468]: src_loss_class=0.236043, src_loss_domain=0.632837, tgt_loss_domain=0.710092, loss=1.578973\n",
            "Epoch [  29/50] Step [250/468]: src_loss_class=0.258603, src_loss_domain=0.674106, tgt_loss_domain=0.697068, loss=1.629776\n",
            "Epoch [  29/50] Step [300/468]: src_loss_class=0.396625, src_loss_domain=0.681153, tgt_loss_domain=0.670905, loss=1.748682\n",
            "Epoch [  29/50] Step [350/468]: src_loss_class=0.158406, src_loss_domain=0.687196, tgt_loss_domain=0.678079, loss=1.523681\n",
            "Epoch [  29/50] Step [400/468]: src_loss_class=0.231429, src_loss_domain=0.689937, tgt_loss_domain=0.673988, loss=1.595354\n",
            "Epoch [  29/50] Step [450/468]: src_loss_class=0.362248, src_loss_domain=0.641775, tgt_loss_domain=0.688350, loss=1.692373\n",
            "Train SVHN score\n",
            "Avg Loss = 0.003228, Avg Accuracy = 86.80%, 63555.0/73216, Avg Domain Accuracy = 57.006665%\n",
            "Test SVHN score\n",
            "Avg Loss = 0.003545, Avg Accuracy = 86.01%, 22348.0/25984, Avg Domain Accuracy = 54.752925%\n",
            "Test MNIST score\n",
            "Avg Loss = 0.009811, Avg Accuracy = 71.33%, 7122.0/9984, Avg Domain Accuracy = 62.580128%\n",
            "Epoch [  30/50] Step [50/468]: src_loss_class=0.222093, src_loss_domain=0.735824, tgt_loss_domain=0.713652, loss=1.671569\n",
            "Epoch [  30/50] Step [100/468]: src_loss_class=0.281515, src_loss_domain=0.672185, tgt_loss_domain=0.690201, loss=1.643901\n",
            "Epoch [  30/50] Step [150/468]: src_loss_class=0.336531, src_loss_domain=0.672495, tgt_loss_domain=0.729303, loss=1.738330\n",
            "Epoch [  30/50] Step [200/468]: src_loss_class=0.237529, src_loss_domain=0.672538, tgt_loss_domain=0.677053, loss=1.587119\n",
            "Epoch [  30/50] Step [250/468]: src_loss_class=0.314294, src_loss_domain=0.775339, tgt_loss_domain=0.574445, loss=1.664079\n",
            "Epoch [  30/50] Step [300/468]: src_loss_class=0.377490, src_loss_domain=0.663393, tgt_loss_domain=0.667016, loss=1.707899\n",
            "Epoch [  30/50] Step [350/468]: src_loss_class=0.311509, src_loss_domain=0.649001, tgt_loss_domain=0.648760, loss=1.609271\n",
            "Epoch [  30/50] Step [400/468]: src_loss_class=0.197056, src_loss_domain=0.647693, tgt_loss_domain=0.671855, loss=1.516605\n",
            "Epoch [  30/50] Step [450/468]: src_loss_class=0.302555, src_loss_domain=0.676593, tgt_loss_domain=0.666636, loss=1.645784\n",
            "Train SVHN score\n",
            "Avg Loss = 0.003180, Avg Accuracy = 87.08%, 63758.0/73216, Avg Domain Accuracy = 75.939685%\n",
            "Test SVHN score\n",
            "Avg Loss = 0.003592, Avg Accuracy = 86.09%, 22369.0/25984, Avg Domain Accuracy = 75.504156%\n",
            "Test MNIST score\n",
            "Avg Loss = 0.010194, Avg Accuracy = 70.91%, 7080.0/9984, Avg Domain Accuracy = 43.439503%\n",
            "Epoch [  31/50] Step [50/468]: src_loss_class=0.220232, src_loss_domain=0.664180, tgt_loss_domain=0.695123, loss=1.579535\n",
            "Epoch [  31/50] Step [100/468]: src_loss_class=0.337923, src_loss_domain=0.689362, tgt_loss_domain=0.690368, loss=1.717653\n",
            "Epoch [  31/50] Step [150/468]: src_loss_class=0.240497, src_loss_domain=0.680465, tgt_loss_domain=0.704787, loss=1.625748\n",
            "Epoch [  31/50] Step [200/468]: src_loss_class=0.230314, src_loss_domain=0.713631, tgt_loss_domain=0.655754, loss=1.599698\n",
            "Epoch [  31/50] Step [250/468]: src_loss_class=0.480777, src_loss_domain=0.663863, tgt_loss_domain=0.716328, loss=1.860968\n",
            "Epoch [  31/50] Step [300/468]: src_loss_class=0.386564, src_loss_domain=0.630035, tgt_loss_domain=0.686735, loss=1.703334\n",
            "Epoch [  31/50] Step [350/468]: src_loss_class=0.456399, src_loss_domain=0.725139, tgt_loss_domain=0.664647, loss=1.846185\n",
            "Epoch [  31/50] Step [400/468]: src_loss_class=0.321187, src_loss_domain=0.647473, tgt_loss_domain=0.719643, loss=1.688302\n",
            "Epoch [  31/50] Step [450/468]: src_loss_class=0.172710, src_loss_domain=0.707606, tgt_loss_domain=0.670154, loss=1.550471\n",
            "Train SVHN score\n",
            "Avg Loss = 0.003086, Avg Accuracy = 87.37%, 63972.0/73216, Avg Domain Accuracy = 57.197880%\n",
            "Test SVHN score\n",
            "Avg Loss = 0.003609, Avg Accuracy = 85.73%, 22275.0/25984, Avg Domain Accuracy = 56.403941%\n",
            "Test MNIST score\n",
            "Avg Loss = 0.010729, Avg Accuracy = 70.77%, 7066.0/9984, Avg Domain Accuracy = 56.710737%\n",
            "Epoch [  32/50] Step [50/468]: src_loss_class=0.196538, src_loss_domain=0.779911, tgt_loss_domain=0.668683, loss=1.645132\n",
            "Epoch [  32/50] Step [100/468]: src_loss_class=0.334337, src_loss_domain=0.673508, tgt_loss_domain=0.709064, loss=1.716908\n",
            "Epoch [  32/50] Step [150/468]: src_loss_class=0.350806, src_loss_domain=0.670138, tgt_loss_domain=0.707699, loss=1.728643\n",
            "Epoch [  32/50] Step [200/468]: src_loss_class=0.275890, src_loss_domain=0.750010, tgt_loss_domain=0.607971, loss=1.633872\n",
            "Epoch [  32/50] Step [250/468]: src_loss_class=0.279338, src_loss_domain=0.766206, tgt_loss_domain=0.584351, loss=1.629894\n",
            "Epoch [  32/50] Step [300/468]: src_loss_class=0.440241, src_loss_domain=0.683440, tgt_loss_domain=0.717480, loss=1.841161\n",
            "Epoch [  32/50] Step [350/468]: src_loss_class=0.176402, src_loss_domain=0.694516, tgt_loss_domain=0.649721, loss=1.520639\n",
            "Epoch [  32/50] Step [400/468]: src_loss_class=0.246767, src_loss_domain=0.706283, tgt_loss_domain=0.712166, loss=1.665217\n",
            "Epoch [  32/50] Step [450/468]: src_loss_class=0.476665, src_loss_domain=0.714138, tgt_loss_domain=0.663214, loss=1.854017\n",
            "Train SVHN score\n",
            "Avg Loss = 0.003541, Avg Accuracy = 85.34%, 62479.0/73216, Avg Domain Accuracy = 62.863309%\n",
            "Test SVHN score\n",
            "Avg Loss = 0.003962, Avg Accuracy = 84.11%, 21854.0/25984, Avg Domain Accuracy = 61.841903%\n",
            "Test MNIST score\n",
            "Avg Loss = 0.011385, Avg Accuracy = 69.18%, 6907.0/9984, Avg Domain Accuracy = 50.671074%\n",
            "Epoch [  33/50] Step [50/468]: src_loss_class=0.307947, src_loss_domain=0.640836, tgt_loss_domain=0.706014, loss=1.654796\n",
            "Epoch [  33/50] Step [100/468]: src_loss_class=0.333067, src_loss_domain=0.647642, tgt_loss_domain=0.686925, loss=1.667634\n",
            "Epoch [  33/50] Step [150/468]: src_loss_class=0.358609, src_loss_domain=0.608853, tgt_loss_domain=0.730380, loss=1.697843\n",
            "Epoch [  33/50] Step [200/468]: src_loss_class=0.240846, src_loss_domain=0.669628, tgt_loss_domain=0.656656, loss=1.567130\n",
            "Epoch [  33/50] Step [250/468]: src_loss_class=0.324614, src_loss_domain=0.659751, tgt_loss_domain=0.673388, loss=1.657752\n",
            "Epoch [  33/50] Step [300/468]: src_loss_class=0.261745, src_loss_domain=0.667351, tgt_loss_domain=0.687279, loss=1.616376\n",
            "Epoch [  33/50] Step [350/468]: src_loss_class=0.354005, src_loss_domain=0.681491, tgt_loss_domain=0.715237, loss=1.750732\n",
            "Epoch [  33/50] Step [400/468]: src_loss_class=0.214317, src_loss_domain=0.646476, tgt_loss_domain=0.702680, loss=1.563474\n",
            "Epoch [  33/50] Step [450/468]: src_loss_class=0.439160, src_loss_domain=0.753970, tgt_loss_domain=0.631017, loss=1.824147\n",
            "Train SVHN score\n",
            "Avg Loss = 0.003193, Avg Accuracy = 86.91%, 63631.0/73216, Avg Domain Accuracy = 59.552557%\n",
            "Test SVHN score\n",
            "Avg Loss = 0.003707, Avg Accuracy = 85.29%, 22163.0/25984, Avg Domain Accuracy = 56.904249%\n",
            "Test MNIST score\n",
            "Avg Loss = 0.011584, Avg Accuracy = 69.40%, 6929.0/9984, Avg Domain Accuracy = 52.013221%\n",
            "Epoch [  34/50] Step [50/468]: src_loss_class=0.241545, src_loss_domain=0.715009, tgt_loss_domain=0.666532, loss=1.623086\n",
            "Epoch [  34/50] Step [100/468]: src_loss_class=0.408864, src_loss_domain=0.700560, tgt_loss_domain=0.701714, loss=1.811137\n",
            "Epoch [  34/50] Step [150/468]: src_loss_class=0.301018, src_loss_domain=0.661056, tgt_loss_domain=0.741636, loss=1.703709\n",
            "Epoch [  34/50] Step [200/468]: src_loss_class=0.148221, src_loss_domain=0.647181, tgt_loss_domain=0.731040, loss=1.526441\n",
            "Epoch [  34/50] Step [250/468]: src_loss_class=0.192197, src_loss_domain=0.660183, tgt_loss_domain=0.656324, loss=1.508704\n",
            "Epoch [  34/50] Step [300/468]: src_loss_class=0.265433, src_loss_domain=0.766225, tgt_loss_domain=0.584025, loss=1.615683\n",
            "Epoch [  34/50] Step [350/468]: src_loss_class=0.304935, src_loss_domain=0.670481, tgt_loss_domain=0.677352, loss=1.652767\n",
            "Epoch [  34/50] Step [400/468]: src_loss_class=0.407696, src_loss_domain=0.634884, tgt_loss_domain=0.670028, loss=1.712608\n",
            "Epoch [  34/50] Step [450/468]: src_loss_class=0.276419, src_loss_domain=0.719043, tgt_loss_domain=0.640155, loss=1.635616\n",
            "Train SVHN score\n",
            "Avg Loss = 0.003362, Avg Accuracy = 85.93%, 62913.0/73216, Avg Domain Accuracy = 61.952306%\n",
            "Test SVHN score\n",
            "Avg Loss = 0.003773, Avg Accuracy = 84.90%, 22060.0/25984, Avg Domain Accuracy = 61.876539%\n",
            "Test MNIST score\n",
            "Avg Loss = 0.010516, Avg Accuracy = 71.19%, 7108.0/9984, Avg Domain Accuracy = 51.262019%\n",
            "Epoch [  35/50] Step [50/468]: src_loss_class=0.322567, src_loss_domain=0.714658, tgt_loss_domain=0.673355, loss=1.710581\n",
            "Epoch [  35/50] Step [100/468]: src_loss_class=0.355016, src_loss_domain=0.673608, tgt_loss_domain=0.645606, loss=1.674230\n",
            "Epoch [  35/50] Step [150/468]: src_loss_class=0.372135, src_loss_domain=0.701525, tgt_loss_domain=0.706374, loss=1.780035\n",
            "Epoch [  35/50] Step [200/468]: src_loss_class=0.380227, src_loss_domain=0.720341, tgt_loss_domain=0.707269, loss=1.807837\n",
            "Epoch [  35/50] Step [250/468]: src_loss_class=0.205304, src_loss_domain=0.675081, tgt_loss_domain=0.696819, loss=1.577204\n",
            "Epoch [  35/50] Step [300/468]: src_loss_class=0.171937, src_loss_domain=0.668770, tgt_loss_domain=0.732924, loss=1.573631\n",
            "Epoch [  35/50] Step [350/468]: src_loss_class=0.331977, src_loss_domain=0.681144, tgt_loss_domain=0.629109, loss=1.642231\n",
            "Epoch [  35/50] Step [400/468]: src_loss_class=0.282251, src_loss_domain=0.568372, tgt_loss_domain=0.730740, loss=1.581363\n",
            "Epoch [  35/50] Step [450/468]: src_loss_class=0.241706, src_loss_domain=0.708679, tgt_loss_domain=0.682125, loss=1.632510\n",
            "Train SVHN score\n",
            "Avg Loss = 0.003052, Avg Accuracy = 87.51%, 64070.0/73216, Avg Domain Accuracy = 48.269504%\n",
            "Test SVHN score\n",
            "Avg Loss = 0.003391, Avg Accuracy = 86.57%, 22494.0/25984, Avg Domain Accuracy = 47.390702%\n",
            "Test MNIST score\n",
            "Avg Loss = 0.010771, Avg Accuracy = 71.44%, 7133.0/9984, Avg Domain Accuracy = 70.653045%\n",
            "Epoch [  36/50] Step [50/468]: src_loss_class=0.219163, src_loss_domain=0.671793, tgt_loss_domain=0.653827, loss=1.544783\n",
            "Epoch [  36/50] Step [100/468]: src_loss_class=0.452135, src_loss_domain=0.649151, tgt_loss_domain=0.697575, loss=1.798861\n",
            "Epoch [  36/50] Step [150/468]: src_loss_class=0.246832, src_loss_domain=0.676935, tgt_loss_domain=0.639576, loss=1.563344\n",
            "Epoch [  36/50] Step [200/468]: src_loss_class=0.258859, src_loss_domain=0.669486, tgt_loss_domain=0.702117, loss=1.630462\n",
            "Epoch [  36/50] Step [250/468]: src_loss_class=0.182855, src_loss_domain=0.636523, tgt_loss_domain=0.723717, loss=1.543094\n",
            "Epoch [  36/50] Step [300/468]: src_loss_class=0.242939, src_loss_domain=0.657512, tgt_loss_domain=0.677512, loss=1.577963\n",
            "Epoch [  36/50] Step [350/468]: src_loss_class=0.387378, src_loss_domain=0.707646, tgt_loss_domain=0.648801, loss=1.743825\n",
            "Epoch [  36/50] Step [400/468]: src_loss_class=0.273082, src_loss_domain=0.632992, tgt_loss_domain=0.722275, loss=1.628349\n",
            "Epoch [  36/50] Step [450/468]: src_loss_class=0.512402, src_loss_domain=0.696239, tgt_loss_domain=0.649564, loss=1.858205\n",
            "Train SVHN score\n",
            "Avg Loss = 0.003121, Avg Accuracy = 87.48%, 64046.0/73216, Avg Domain Accuracy = 65.022673%\n",
            "Test SVHN score\n",
            "Avg Loss = 0.003721, Avg Accuracy = 85.52%, 22222.0/25984, Avg Domain Accuracy = 64.004772%\n",
            "Test MNIST score\n",
            "Avg Loss = 0.011664, Avg Accuracy = 70.11%, 7000.0/9984, Avg Domain Accuracy = 48.497596%\n",
            "Epoch [  37/50] Step [50/468]: src_loss_class=0.265215, src_loss_domain=0.691925, tgt_loss_domain=0.669067, loss=1.626207\n",
            "Epoch [  37/50] Step [100/468]: src_loss_class=0.304505, src_loss_domain=0.677536, tgt_loss_domain=0.705578, loss=1.687620\n",
            "Epoch [  37/50] Step [150/468]: src_loss_class=0.319347, src_loss_domain=0.710300, tgt_loss_domain=0.693723, loss=1.723370\n",
            "Epoch [  37/50] Step [200/468]: src_loss_class=0.263223, src_loss_domain=0.694119, tgt_loss_domain=0.667222, loss=1.624564\n",
            "Epoch [  37/50] Step [250/468]: src_loss_class=0.264028, src_loss_domain=0.644178, tgt_loss_domain=0.688497, loss=1.596703\n",
            "Epoch [  37/50] Step [300/468]: src_loss_class=0.225150, src_loss_domain=0.639294, tgt_loss_domain=0.681026, loss=1.545471\n",
            "Epoch [  37/50] Step [350/468]: src_loss_class=0.234355, src_loss_domain=0.715143, tgt_loss_domain=0.669561, loss=1.619059\n",
            "Epoch [  37/50] Step [400/468]: src_loss_class=0.332850, src_loss_domain=0.722743, tgt_loss_domain=0.702957, loss=1.758549\n",
            "Epoch [  37/50] Step [450/468]: src_loss_class=0.352399, src_loss_domain=0.694099, tgt_loss_domain=0.634947, loss=1.681445\n",
            "Train SVHN score\n",
            "Avg Loss = 0.003189, Avg Accuracy = 86.80%, 63551.0/73216, Avg Domain Accuracy = 58.151224%\n",
            "Test SVHN score\n",
            "Avg Loss = 0.003580, Avg Accuracy = 85.73%, 22276.0/25984, Avg Domain Accuracy = 58.216595%\n",
            "Test MNIST score\n",
            "Avg Loss = 0.010611, Avg Accuracy = 71.96%, 7184.0/9984, Avg Domain Accuracy = 62.880609%\n",
            "Epoch [  38/50] Step [50/468]: src_loss_class=0.309111, src_loss_domain=0.726665, tgt_loss_domain=0.684646, loss=1.720423\n",
            "Epoch [  38/50] Step [100/468]: src_loss_class=0.325945, src_loss_domain=0.599431, tgt_loss_domain=0.731928, loss=1.657305\n",
            "Epoch [  38/50] Step [150/468]: src_loss_class=0.176784, src_loss_domain=0.671318, tgt_loss_domain=0.696291, loss=1.544392\n",
            "Epoch [  38/50] Step [200/468]: src_loss_class=0.226111, src_loss_domain=0.760311, tgt_loss_domain=0.718086, loss=1.704507\n",
            "Epoch [  38/50] Step [250/468]: src_loss_class=0.323891, src_loss_domain=0.680371, tgt_loss_domain=0.657382, loss=1.661643\n",
            "Epoch [  38/50] Step [300/468]: src_loss_class=0.237760, src_loss_domain=0.746972, tgt_loss_domain=0.658805, loss=1.643537\n",
            "Epoch [  38/50] Step [350/468]: src_loss_class=0.206439, src_loss_domain=0.647219, tgt_loss_domain=0.693029, loss=1.546686\n",
            "Epoch [  38/50] Step [400/468]: src_loss_class=0.288735, src_loss_domain=0.672528, tgt_loss_domain=0.687069, loss=1.648332\n",
            "Epoch [  38/50] Step [450/468]: src_loss_class=0.190232, src_loss_domain=0.700049, tgt_loss_domain=0.703084, loss=1.593364\n",
            "Train SVHN score\n",
            "Avg Loss = 0.002961, Avg Accuracy = 88.26%, 64621.0/73216, Avg Domain Accuracy = 63.722410%\n",
            "Test SVHN score\n",
            "Avg Loss = 0.003417, Avg Accuracy = 86.86%, 22571.0/25984, Avg Domain Accuracy = 62.642395%\n",
            "Test MNIST score\n",
            "Avg Loss = 0.012691, Avg Accuracy = 69.04%, 6893.0/9984, Avg Domain Accuracy = 47.766426%\n",
            "Epoch [  39/50] Step [50/468]: src_loss_class=0.203038, src_loss_domain=0.676568, tgt_loss_domain=0.699800, loss=1.579405\n",
            "Epoch [  39/50] Step [100/468]: src_loss_class=0.379496, src_loss_domain=0.675303, tgt_loss_domain=0.699317, loss=1.754116\n",
            "Epoch [  39/50] Step [150/468]: src_loss_class=0.220098, src_loss_domain=0.670700, tgt_loss_domain=0.702042, loss=1.592840\n",
            "Epoch [  39/50] Step [200/468]: src_loss_class=0.287432, src_loss_domain=0.704441, tgt_loss_domain=0.657830, loss=1.649703\n",
            "Epoch [  39/50] Step [250/468]: src_loss_class=0.397510, src_loss_domain=0.697009, tgt_loss_domain=0.675745, loss=1.770265\n",
            "Epoch [  39/50] Step [300/468]: src_loss_class=0.329321, src_loss_domain=0.727707, tgt_loss_domain=0.641621, loss=1.698648\n",
            "Epoch [  39/50] Step [350/468]: src_loss_class=0.185762, src_loss_domain=0.691935, tgt_loss_domain=0.658320, loss=1.536017\n",
            "Epoch [  39/50] Step [400/468]: src_loss_class=0.368924, src_loss_domain=0.720193, tgt_loss_domain=0.654322, loss=1.743438\n",
            "Epoch [  39/50] Step [450/468]: src_loss_class=0.307257, src_loss_domain=0.666728, tgt_loss_domain=0.633101, loss=1.607086\n",
            "Train SVHN score\n",
            "Avg Loss = 0.003172, Avg Accuracy = 87.08%, 63757.0/73216, Avg Domain Accuracy = 66.346154%\n",
            "Test SVHN score\n",
            "Avg Loss = 0.003630, Avg Accuracy = 85.77%, 22286.0/25984, Avg Domain Accuracy = 63.373615%\n",
            "Test MNIST score\n",
            "Avg Loss = 0.012131, Avg Accuracy = 70.22%, 7011.0/9984, Avg Domain Accuracy = 50.290465%\n",
            "Epoch [  40/50] Step [50/468]: src_loss_class=0.296606, src_loss_domain=0.697145, tgt_loss_domain=0.659188, loss=1.652939\n",
            "Epoch [  40/50] Step [100/468]: src_loss_class=0.178073, src_loss_domain=0.642221, tgt_loss_domain=0.735922, loss=1.556217\n",
            "Epoch [  40/50] Step [150/468]: src_loss_class=0.195769, src_loss_domain=0.630269, tgt_loss_domain=0.702072, loss=1.528111\n",
            "Epoch [  40/50] Step [200/468]: src_loss_class=0.370232, src_loss_domain=0.657978, tgt_loss_domain=0.675056, loss=1.703266\n",
            "Epoch [  40/50] Step [250/468]: src_loss_class=0.315197, src_loss_domain=0.656581, tgt_loss_domain=0.679362, loss=1.651139\n",
            "Epoch [  40/50] Step [300/468]: src_loss_class=0.303002, src_loss_domain=0.657098, tgt_loss_domain=0.702837, loss=1.662937\n",
            "Epoch [  40/50] Step [350/468]: src_loss_class=0.357794, src_loss_domain=0.678871, tgt_loss_domain=0.728645, loss=1.765309\n",
            "Epoch [  40/50] Step [400/468]: src_loss_class=0.200083, src_loss_domain=0.639079, tgt_loss_domain=0.678085, loss=1.517246\n",
            "Epoch [  40/50] Step [450/468]: src_loss_class=0.269271, src_loss_domain=0.778322, tgt_loss_domain=0.646164, loss=1.693758\n",
            "Train SVHN score\n",
            "Avg Loss = 0.003086, Avg Accuracy = 87.34%, 63948.0/73216, Avg Domain Accuracy = 63.025841%\n",
            "Test SVHN score\n",
            "Avg Loss = 0.003480, Avg Accuracy = 86.33%, 22431.0/25984, Avg Domain Accuracy = 61.680265%\n",
            "Test MNIST score\n",
            "Avg Loss = 0.012395, Avg Accuracy = 70.01%, 6990.0/9984, Avg Domain Accuracy = 59.905849%\n",
            "Epoch [  41/50] Step [50/468]: src_loss_class=0.204891, src_loss_domain=0.656463, tgt_loss_domain=0.676555, loss=1.537910\n",
            "Epoch [  41/50] Step [100/468]: src_loss_class=0.393602, src_loss_domain=0.662866, tgt_loss_domain=0.738465, loss=1.794932\n",
            "Epoch [  41/50] Step [150/468]: src_loss_class=0.368470, src_loss_domain=0.756580, tgt_loss_domain=0.625211, loss=1.750261\n",
            "Epoch [  41/50] Step [200/468]: src_loss_class=0.446269, src_loss_domain=0.724049, tgt_loss_domain=0.668461, loss=1.838779\n",
            "Epoch [  41/50] Step [250/468]: src_loss_class=0.289180, src_loss_domain=0.724268, tgt_loss_domain=0.681836, loss=1.695284\n",
            "Epoch [  41/50] Step [300/468]: src_loss_class=0.478749, src_loss_domain=0.709447, tgt_loss_domain=0.656099, loss=1.844295\n",
            "Epoch [  41/50] Step [350/468]: src_loss_class=0.400487, src_loss_domain=0.681513, tgt_loss_domain=0.679484, loss=1.761484\n",
            "Epoch [  41/50] Step [400/468]: src_loss_class=0.248470, src_loss_domain=0.664882, tgt_loss_domain=0.743602, loss=1.656953\n",
            "Epoch [  41/50] Step [450/468]: src_loss_class=0.265791, src_loss_domain=0.686957, tgt_loss_domain=0.665413, loss=1.618161\n",
            "Train SVHN score\n",
            "Avg Loss = 0.002964, Avg Accuracy = 88.06%, 64477.0/73216, Avg Domain Accuracy = 67.273547%\n",
            "Test SVHN score\n",
            "Avg Loss = 0.003411, Avg Accuracy = 86.67%, 22521.0/25984, Avg Domain Accuracy = 65.213208%\n",
            "Test MNIST score\n",
            "Avg Loss = 0.012105, Avg Accuracy = 70.09%, 6998.0/9984, Avg Domain Accuracy = 54.387019%\n",
            "Epoch [  42/50] Step [50/468]: src_loss_class=0.274358, src_loss_domain=0.684253, tgt_loss_domain=0.655075, loss=1.613686\n",
            "Epoch [  42/50] Step [100/468]: src_loss_class=0.262160, src_loss_domain=0.675719, tgt_loss_domain=0.672498, loss=1.610377\n",
            "Epoch [  42/50] Step [150/468]: src_loss_class=0.268536, src_loss_domain=0.642156, tgt_loss_domain=0.654738, loss=1.565430\n",
            "Epoch [  42/50] Step [200/468]: src_loss_class=0.367673, src_loss_domain=0.698517, tgt_loss_domain=0.679231, loss=1.745420\n",
            "Epoch [  42/50] Step [250/468]: src_loss_class=0.300825, src_loss_domain=0.739894, tgt_loss_domain=0.656657, loss=1.697376\n",
            "Epoch [  42/50] Step [300/468]: src_loss_class=0.339575, src_loss_domain=0.678441, tgt_loss_domain=0.677449, loss=1.695465\n",
            "Epoch [  42/50] Step [350/468]: src_loss_class=0.294933, src_loss_domain=0.695133, tgt_loss_domain=0.661072, loss=1.651139\n",
            "Epoch [  42/50] Step [400/468]: src_loss_class=0.251916, src_loss_domain=0.686949, tgt_loss_domain=0.694204, loss=1.633068\n",
            "Epoch [  42/50] Step [450/468]: src_loss_class=0.253292, src_loss_domain=0.669198, tgt_loss_domain=0.673661, loss=1.596152\n",
            "Train SVHN score\n",
            "Avg Loss = 0.002957, Avg Accuracy = 88.12%, 64517.0/73216, Avg Domain Accuracy = 72.940341%\n",
            "Test SVHN score\n",
            "Avg Loss = 0.003404, Avg Accuracy = 86.56%, 22492.0/25984, Avg Domain Accuracy = 73.410560%\n",
            "Test MNIST score\n",
            "Avg Loss = 0.011202, Avg Accuracy = 70.50%, 7039.0/9984, Avg Domain Accuracy = 40.584936%\n",
            "Epoch [  43/50] Step [50/468]: src_loss_class=0.223071, src_loss_domain=0.664086, tgt_loss_domain=0.678929, loss=1.566086\n",
            "Epoch [  43/50] Step [100/468]: src_loss_class=0.352665, src_loss_domain=0.606366, tgt_loss_domain=0.715355, loss=1.674385\n",
            "Epoch [  43/50] Step [150/468]: src_loss_class=0.295573, src_loss_domain=0.658467, tgt_loss_domain=0.689902, loss=1.643943\n",
            "Epoch [  43/50] Step [200/468]: src_loss_class=0.427177, src_loss_domain=0.710901, tgt_loss_domain=0.717663, loss=1.855741\n",
            "Epoch [  43/50] Step [250/468]: src_loss_class=0.368323, src_loss_domain=0.637002, tgt_loss_domain=0.704815, loss=1.710140\n",
            "Epoch [  43/50] Step [300/468]: src_loss_class=0.317211, src_loss_domain=0.672914, tgt_loss_domain=0.679673, loss=1.669799\n",
            "Epoch [  43/50] Step [350/468]: src_loss_class=0.302139, src_loss_domain=0.704270, tgt_loss_domain=0.636283, loss=1.642693\n",
            "Epoch [  43/50] Step [400/468]: src_loss_class=0.324693, src_loss_domain=0.683998, tgt_loss_domain=0.660377, loss=1.669068\n",
            "Epoch [  43/50] Step [450/468]: src_loss_class=0.344142, src_loss_domain=0.681151, tgt_loss_domain=0.634802, loss=1.660095\n",
            "Train SVHN score\n",
            "Avg Loss = 0.003045, Avg Accuracy = 87.72%, 64225.0/73216, Avg Domain Accuracy = 69.977874%\n",
            "Test SVHN score\n",
            "Avg Loss = 0.003494, Avg Accuracy = 86.44%, 22460.0/25984, Avg Domain Accuracy = 71.309267%\n",
            "Test MNIST score\n",
            "Avg Loss = 0.011583, Avg Accuracy = 71.67%, 7156.0/9984, Avg Domain Accuracy = 55.158253%\n",
            "Epoch [  44/50] Step [50/468]: src_loss_class=0.269988, src_loss_domain=0.625881, tgt_loss_domain=0.698323, loss=1.594192\n",
            "Epoch [  44/50] Step [100/468]: src_loss_class=0.359244, src_loss_domain=0.763779, tgt_loss_domain=0.679183, loss=1.802206\n",
            "Epoch [  44/50] Step [150/468]: src_loss_class=0.331291, src_loss_domain=0.643031, tgt_loss_domain=0.671958, loss=1.646279\n",
            "Epoch [  44/50] Step [200/468]: src_loss_class=0.290330, src_loss_domain=0.692989, tgt_loss_domain=0.709184, loss=1.692504\n",
            "Epoch [  44/50] Step [250/468]: src_loss_class=0.334076, src_loss_domain=0.665603, tgt_loss_domain=0.704085, loss=1.703763\n",
            "Epoch [  44/50] Step [300/468]: src_loss_class=0.257983, src_loss_domain=0.711647, tgt_loss_domain=0.669580, loss=1.639210\n",
            "Epoch [  44/50] Step [350/468]: src_loss_class=0.405352, src_loss_domain=0.652042, tgt_loss_domain=0.721311, loss=1.778706\n",
            "Epoch [  44/50] Step [400/468]: src_loss_class=0.467234, src_loss_domain=0.677439, tgt_loss_domain=0.672145, loss=1.816819\n",
            "Epoch [  44/50] Step [450/468]: src_loss_class=0.170693, src_loss_domain=0.683365, tgt_loss_domain=0.651062, loss=1.505121\n",
            "Train SVHN score\n",
            "Avg Loss = 0.002903, Avg Accuracy = 88.14%, 64535.0/73216, Avg Domain Accuracy = 64.058403%\n",
            "Test SVHN score\n",
            "Avg Loss = 0.003419, Avg Accuracy = 86.68%, 22523.0/25984, Avg Domain Accuracy = 63.889317%\n",
            "Test MNIST score\n",
            "Avg Loss = 0.012348, Avg Accuracy = 70.26%, 7015.0/9984, Avg Domain Accuracy = 56.229968%\n",
            "Epoch [  45/50] Step [50/468]: src_loss_class=0.307663, src_loss_domain=0.667436, tgt_loss_domain=0.703813, loss=1.678913\n",
            "Epoch [  45/50] Step [100/468]: src_loss_class=0.259081, src_loss_domain=0.649862, tgt_loss_domain=0.715384, loss=1.624327\n",
            "Epoch [  45/50] Step [150/468]: src_loss_class=0.294442, src_loss_domain=0.709142, tgt_loss_domain=0.658878, loss=1.662462\n",
            "Epoch [  45/50] Step [200/468]: src_loss_class=0.346242, src_loss_domain=0.675545, tgt_loss_domain=0.668876, loss=1.690663\n",
            "Epoch [  45/50] Step [250/468]: src_loss_class=0.231993, src_loss_domain=0.644278, tgt_loss_domain=0.700792, loss=1.577063\n",
            "Epoch [  45/50] Step [300/468]: src_loss_class=0.245729, src_loss_domain=0.641135, tgt_loss_domain=0.693709, loss=1.580572\n",
            "Epoch [  45/50] Step [350/468]: src_loss_class=0.188966, src_loss_domain=0.681250, tgt_loss_domain=0.663782, loss=1.533998\n",
            "Epoch [  45/50] Step [400/468]: src_loss_class=0.238231, src_loss_domain=0.642495, tgt_loss_domain=0.735370, loss=1.616096\n",
            "Epoch [  45/50] Step [450/468]: src_loss_class=0.279099, src_loss_domain=0.699880, tgt_loss_domain=0.706860, loss=1.685839\n",
            "Train SVHN score\n",
            "Avg Loss = 0.002978, Avg Accuracy = 87.86%, 64325.0/73216, Avg Domain Accuracy = 66.026552%\n",
            "Test SVHN score\n",
            "Avg Loss = 0.003457, Avg Accuracy = 86.50%, 22477.0/25984, Avg Domain Accuracy = 66.044489%\n",
            "Test MNIST score\n",
            "Avg Loss = 0.012943, Avg Accuracy = 69.31%, 6920.0/9984, Avg Domain Accuracy = 51.522436%\n",
            "Epoch [  46/50] Step [50/468]: src_loss_class=0.289876, src_loss_domain=0.716568, tgt_loss_domain=0.616148, loss=1.622591\n",
            "Epoch [  46/50] Step [100/468]: src_loss_class=0.316589, src_loss_domain=0.709705, tgt_loss_domain=0.685263, loss=1.711558\n",
            "Epoch [  46/50] Step [150/468]: src_loss_class=0.407815, src_loss_domain=0.644396, tgt_loss_domain=0.640419, loss=1.692631\n",
            "Epoch [  46/50] Step [200/468]: src_loss_class=0.351232, src_loss_domain=0.659698, tgt_loss_domain=0.676205, loss=1.687136\n",
            "Epoch [  46/50] Step [250/468]: src_loss_class=0.204050, src_loss_domain=0.738593, tgt_loss_domain=0.739737, loss=1.682380\n",
            "Epoch [  46/50] Step [300/468]: src_loss_class=0.331236, src_loss_domain=0.702629, tgt_loss_domain=0.699536, loss=1.733401\n",
            "Epoch [  46/50] Step [350/468]: src_loss_class=0.353369, src_loss_domain=0.692259, tgt_loss_domain=0.649618, loss=1.695246\n",
            "Epoch [  46/50] Step [400/468]: src_loss_class=0.284624, src_loss_domain=0.681737, tgt_loss_domain=0.666988, loss=1.633349\n",
            "Epoch [  46/50] Step [450/468]: src_loss_class=0.312869, src_loss_domain=0.678045, tgt_loss_domain=0.689600, loss=1.680514\n",
            "Train SVHN score\n",
            "Avg Loss = 0.003298, Avg Accuracy = 86.33%, 63211.0/73216, Avg Domain Accuracy = 48.496230%\n",
            "Test SVHN score\n",
            "Avg Loss = 0.003710, Avg Accuracy = 85.16%, 22129.0/25984, Avg Domain Accuracy = 46.782635%\n",
            "Test MNIST score\n",
            "Avg Loss = 0.011001, Avg Accuracy = 72.01%, 7189.0/9984, Avg Domain Accuracy = 57.011218%\n",
            "Epoch [  47/50] Step [50/468]: src_loss_class=0.319455, src_loss_domain=0.607667, tgt_loss_domain=0.661887, loss=1.589010\n",
            "Epoch [  47/50] Step [100/468]: src_loss_class=0.111482, src_loss_domain=0.706998, tgt_loss_domain=0.686864, loss=1.505344\n",
            "Epoch [  47/50] Step [150/468]: src_loss_class=0.168465, src_loss_domain=0.625184, tgt_loss_domain=0.709678, loss=1.503327\n",
            "Epoch [  47/50] Step [200/468]: src_loss_class=0.382931, src_loss_domain=0.605845, tgt_loss_domain=0.733022, loss=1.721798\n",
            "Epoch [  47/50] Step [250/468]: src_loss_class=0.318104, src_loss_domain=0.695369, tgt_loss_domain=0.670689, loss=1.684162\n",
            "Epoch [  47/50] Step [300/468]: src_loss_class=0.198517, src_loss_domain=0.691450, tgt_loss_domain=0.631121, loss=1.521088\n",
            "Epoch [  47/50] Step [350/468]: src_loss_class=0.228746, src_loss_domain=0.666966, tgt_loss_domain=0.657629, loss=1.553341\n",
            "Epoch [  47/50] Step [400/468]: src_loss_class=0.313780, src_loss_domain=0.691770, tgt_loss_domain=0.676540, loss=1.682091\n",
            "Epoch [  47/50] Step [450/468]: src_loss_class=0.217621, src_loss_domain=0.663745, tgt_loss_domain=0.690535, loss=1.571900\n",
            "Train SVHN score\n",
            "Avg Loss = 0.002883, Avg Accuracy = 88.32%, 64663.0/73216, Avg Domain Accuracy = 60.871941%\n",
            "Test SVHN score\n",
            "Avg Loss = 0.003461, Avg Accuracy = 86.46%, 22467.0/25984, Avg Domain Accuracy = 58.747691%\n",
            "Test MNIST score\n",
            "Avg Loss = 0.012321, Avg Accuracy = 70.51%, 7040.0/9984, Avg Domain Accuracy = 51.472356%\n",
            "Epoch [  48/50] Step [50/468]: src_loss_class=0.173427, src_loss_domain=0.698830, tgt_loss_domain=0.728343, loss=1.600600\n",
            "Epoch [  48/50] Step [100/468]: src_loss_class=0.276414, src_loss_domain=0.743604, tgt_loss_domain=0.645009, loss=1.665028\n",
            "Epoch [  48/50] Step [150/468]: src_loss_class=0.277601, src_loss_domain=0.679880, tgt_loss_domain=0.722486, loss=1.679967\n",
            "Epoch [  48/50] Step [200/468]: src_loss_class=0.229942, src_loss_domain=0.662193, tgt_loss_domain=0.637505, loss=1.529640\n",
            "Epoch [  48/50] Step [250/468]: src_loss_class=0.374469, src_loss_domain=0.664571, tgt_loss_domain=0.713182, loss=1.752222\n",
            "Epoch [  48/50] Step [300/468]: src_loss_class=0.334199, src_loss_domain=0.667750, tgt_loss_domain=0.680885, loss=1.682834\n",
            "Epoch [  48/50] Step [350/468]: src_loss_class=0.322707, src_loss_domain=0.646545, tgt_loss_domain=0.688741, loss=1.657994\n",
            "Epoch [  48/50] Step [400/468]: src_loss_class=0.396837, src_loss_domain=0.661168, tgt_loss_domain=0.710599, loss=1.768603\n",
            "Epoch [  48/50] Step [450/468]: src_loss_class=0.235465, src_loss_domain=0.641257, tgt_loss_domain=0.715276, loss=1.591998\n",
            "Train SVHN score\n",
            "Avg Loss = 0.002876, Avg Accuracy = 88.26%, 64623.0/73216, Avg Domain Accuracy = 65.003551%\n",
            "Test SVHN score\n",
            "Avg Loss = 0.003316, Avg Accuracy = 86.92%, 22585.0/25984, Avg Domain Accuracy = 63.373615%\n",
            "Test MNIST score\n",
            "Avg Loss = 0.011069, Avg Accuracy = 72.01%, 7189.0/9984, Avg Domain Accuracy = 53.094952%\n",
            "Epoch [  49/50] Step [50/468]: src_loss_class=0.244630, src_loss_domain=0.727931, tgt_loss_domain=0.688844, loss=1.661405\n",
            "Epoch [  49/50] Step [100/468]: src_loss_class=0.208415, src_loss_domain=0.657183, tgt_loss_domain=0.696870, loss=1.562468\n",
            "Epoch [  49/50] Step [150/468]: src_loss_class=0.379889, src_loss_domain=0.708670, tgt_loss_domain=0.660131, loss=1.748690\n",
            "Epoch [  49/50] Step [200/468]: src_loss_class=0.229284, src_loss_domain=0.637869, tgt_loss_domain=0.707718, loss=1.574872\n",
            "Epoch [  49/50] Step [250/468]: src_loss_class=0.229752, src_loss_domain=0.733421, tgt_loss_domain=0.646314, loss=1.609488\n",
            "Epoch [  49/50] Step [300/468]: src_loss_class=0.213227, src_loss_domain=0.657374, tgt_loss_domain=0.705009, loss=1.575610\n",
            "Epoch [  49/50] Step [350/468]: src_loss_class=0.388520, src_loss_domain=0.710122, tgt_loss_domain=0.692260, loss=1.790902\n",
            "Epoch [  49/50] Step [400/468]: src_loss_class=0.169566, src_loss_domain=0.640808, tgt_loss_domain=0.691528, loss=1.501902\n",
            "Epoch [  49/50] Step [450/468]: src_loss_class=0.191544, src_loss_domain=0.678820, tgt_loss_domain=0.666206, loss=1.536570\n",
            "Train SVHN score\n",
            "Avg Loss = 0.003038, Avg Accuracy = 87.61%, 64141.0/73216, Avg Domain Accuracy = 70.785074%\n",
            "Test SVHN score\n",
            "Avg Loss = 0.003497, Avg Accuracy = 86.14%, 22383.0/25984, Avg Domain Accuracy = 68.134236%\n",
            "Test MNIST score\n",
            "Avg Loss = 0.011149, Avg Accuracy = 72.18%, 7206.0/9984, Avg Domain Accuracy = 48.597756%\n",
            "Epoch [  50/50] Step [50/468]: src_loss_class=0.332996, src_loss_domain=0.641318, tgt_loss_domain=0.725612, loss=1.699926\n",
            "Epoch [  50/50] Step [100/468]: src_loss_class=0.327374, src_loss_domain=0.673377, tgt_loss_domain=0.700234, loss=1.700985\n",
            "Epoch [  50/50] Step [150/468]: src_loss_class=0.285059, src_loss_domain=0.691887, tgt_loss_domain=0.687437, loss=1.664383\n",
            "Epoch [  50/50] Step [200/468]: src_loss_class=0.255834, src_loss_domain=0.668711, tgt_loss_domain=0.656252, loss=1.580797\n",
            "Epoch [  50/50] Step [250/468]: src_loss_class=0.172638, src_loss_domain=0.708367, tgt_loss_domain=0.654690, loss=1.535695\n",
            "Epoch [  50/50] Step [300/468]: src_loss_class=0.215384, src_loss_domain=0.676108, tgt_loss_domain=0.647128, loss=1.538620\n",
            "Epoch [  50/50] Step [350/468]: src_loss_class=0.235638, src_loss_domain=0.673120, tgt_loss_domain=0.712046, loss=1.620804\n",
            "Epoch [  50/50] Step [400/468]: src_loss_class=0.427132, src_loss_domain=0.679250, tgt_loss_domain=0.697697, loss=1.804078\n",
            "Epoch [  50/50] Step [450/468]: src_loss_class=0.214335, src_loss_domain=0.666331, tgt_loss_domain=0.651987, loss=1.532652\n",
            "Train SVHN score\n",
            "Avg Loss = 0.003037, Avg Accuracy = 87.73%, 64229.0/73216, Avg Domain Accuracy = 72.884342%\n",
            "Test SVHN score\n",
            "Avg Loss = 0.003517, Avg Accuracy = 86.20%, 22397.0/25984, Avg Domain Accuracy = 71.724908%\n",
            "Test MNIST score\n",
            "Avg Loss = 0.013174, Avg Accuracy = 69.00%, 6889.0/9984, Avg Domain Accuracy = 52.844551%\n",
            "save pretrained model to: ../data/svhn-mnist/paper-structure_1124_184026/svhn-mnist-dann-final.pt\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}